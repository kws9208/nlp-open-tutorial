{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Sbs7xKpWjb0","executionInfo":{"status":"ok","timestamp":1691500618262,"user_tz":-540,"elapsed":18902,"user":{"displayName":"Wooseok Kim (Wooseok)","userId":"10829587564796253131"}},"outputId":"f1a2ae20-5df8-4fa0-c6f2-4eef1da6e7f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["#Linear Regression"],"metadata":{"id":"8OxmROnXW1gO"}},{"cell_type":"markdown","source":["여러 방법론을 이용한 Linear Regression Optimization"],"metadata":{"id":"KX42QLygXzvx"}},{"cell_type":"markdown","source":["**Dataset load**  \n","\n","data link: https://www.kaggle.com/datasets/andonians/random-linear-regression?resource=download  \n","csv: (comma-separated values) 콤마로 각 데이터가 구분하도록 데이터를 저장한 txt파일"],"metadata":{"id":"rHm1aRYZX7lu"}},{"cell_type":"code","source":["import pandas as pd\n","import os\n","\n","data_path = \"/content/drive/MyDrive/nlp-open-tutorial/1일차_배포/colab/LR_dataset\"\n","train_file = \"train.csv\"\n","test_file = \"test.csv\"\n","\n","df_data = pd.read_csv(os.path.join(data_path, train_file)).dropna()\n","print(df_data)\n","\n","data_list_x = list(df_data.loc[:,\"x\"])\n","data_list_y = list(df_data.loc[:,\"y\"])\n","data_num = len(data_list_x)\n","print(len(data_list_x))\n","print(len(data_list_y))"],"metadata":{"id":"FqMBMADqW5oY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691500622957,"user_tz":-540,"elapsed":2926,"user":{"displayName":"Wooseok Kim (Wooseok)","userId":"10829587564796253131"}},"outputId":"a5286112-39be-4c64-fa2c-981ad63db96a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["        x          y\n","0    24.0  21.549452\n","1    50.0  47.464463\n","2    15.0  17.218656\n","3    38.0  36.586398\n","4    87.0  87.288984\n","..    ...        ...\n","695  58.0  58.595006\n","696  93.0  94.625094\n","697  82.0  88.603770\n","698  66.0  63.648685\n","699  97.0  94.975266\n","\n","[699 rows x 2 columns]\n","699\n","699\n"]}]},{"cell_type":"markdown","source":["**ML hypothesis와 loss function설정**\n","\n","hypo: y = a * x + b  \n","loss: MSE loss (y-y_pred) ^ 2"],"metadata":{"id":"c4h5s94mcFF8"}},{"cell_type":"code","source":["def lr_hypo(a,b,x):\n","  return a * x + b\n","\n","def lr_loss(y, y_pred):\n","  return (y - y_pred)**2"],"metadata":{"id":"SNZ-sfaScJcg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","**Least Square Method**\n","\n","LSM을 사용하여 최적의 parameter a, b를 도출하는 코드 작성"],"metadata":{"id":"BQwvDVcLjGZG"}},{"cell_type":"code","source":["import numpy as np\n","\n","x_mean = np.mean(data_list_x)\n","y_mean = np.mean(data_list_y)\n","\n","a = np.sum((data_list_y - y_mean)*(data_list_x - x_mean)) / np.sum((data_list_x - x_mean)**2)\n","b = y_mean - a * x_mean\n","\n","print(\"a:\", a)\n","print(\"b:\", b)"],"metadata":{"id":"nRDiiM9VjXMn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691500628675,"user_tz":-540,"elapsed":402,"user":{"displayName":"Wooseok Kim (Wooseok)","userId":"10829587564796253131"}},"outputId":"9d3e50aa-d689-40d3-a95c-b173d7ec7bb1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["a: 1.0006563818563037\n","b: -0.10726546430095851\n"]}]},{"cell_type":"markdown","source":["**Gradient Descent**\n","\n","Gradient Descent 방법을 사용하여 parameter a,b를 도출하는 코드 작성"],"metadata":{"id":"jWNr272VqlhB"}},{"cell_type":"markdown","source":["MSE의 미분 if f(x)가 hypo일때  \n","MSE: (f(x) - y) ^ 2 / n  \n","MSE의 편미분: 2 * (f(x) - y)f'(x) / n"],"metadata":{"id":"mmjnQB3iMK_g"}},{"cell_type":"code","source":["def ff_a(a,b,x,y):\n","  return 2 * (a * x + b - y) * x\n","\n","def ff_b(a,b,x,y):\n","  return 2 * (a * x + b - y)\n","\n","a = 10\n","b = -1\n","lr = 0.0001\n","for e in range(100):\n","  print(\"epoch \",e)\n","  loss_sum = 0\n","  grad_a_sum = 0\n","  grad_b_sum = 0\n","  print(\"a:\", a, \", b:\", b)\n","  for i in range(data_num):\n","    y_pred = lr_hypo(a, b, data_list_x[i])\n","    loss_sum += lr_loss(y_pred, data_list_y[i])\n","    grad_a_sum += ff_a(a, b, data_list_x[i], data_list_y[i])\n","    grad_b_sum += ff_b(a, b, data_list_x[i], data_list_y[i])\n","  loss_mean = loss_sum / data_num\n","  a -= lr * (grad_a_sum / data_num)\n","  b -= lr * (grad_b_sum / data_num)\n","  print(\"loss_mean:\",loss_mean)\n","  print(\"\\n\")"],"metadata":{"id":"9Wdd11kYvM73","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691500645026,"user_tz":-540,"elapsed":1042,"user":{"displayName":"Wooseok Kim (Wooseok)","userId":"10829587564796253131"}},"outputId":"2e18b074-7c3b-4c0d-f04b-f7de5ef8d5cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch  0\n","a: 10 , b: -1\n","loss_mean: 269592.02646499267\n","\n","\n","epoch  1\n","a: 3.999891783856498 , b: -1.089840638469199\n","loss_mean: 29746.119276158675\n","\n","\n","epoch  2\n","a: 2.0070720857589617 , b: -1.1196450589576634\n","loss_mean: 3288.5503710140906\n","\n","\n","epoch  3\n","a: 1.3451952876890452 , b: -1.1295096196648944\n","loss_mean: 369.9975150905039\n","\n","\n","epoch  4\n","a: 1.1253652739287507 , b: -1.1327515456973158\n","loss_mean: 48.04989552855042\n","\n","\n","epoch  5\n","a: 1.052352497434899 , b: -1.1337938942226253\n","loss_mean: 12.53560603662213\n","\n","\n","epoch  6\n","a: 1.0281022092822825 , b: -1.1341056976069208\n","loss_mean: 8.617976457246384\n","\n","\n","epoch  7\n","a: 1.0200474327469229 , b: -1.1341748663633533\n","loss_mean: 8.185796416820853\n","\n","\n","epoch  8\n","a: 1.0173716802587056 , b: -1.1341634504741098\n","loss_mean: 8.138098742211975\n","\n","\n","epoch  9\n","a: 1.0164824659585328 , b: -1.1341252716872179\n","loss_mean: 8.132813587224586\n","\n","\n","epoch  10\n","a: 1.0161866155775696 , b: -1.1340782058488348\n","loss_mean: 8.13220698914847\n","\n","\n","epoch  11\n","a: 1.0160878395014237 , b: -1.1340281900733136\n","loss_mean: 8.132116488305503\n","\n","\n","epoch  12\n","a: 1.0160545178464129 , b: -1.1339771962575649\n","loss_mean: 8.13208292087254\n","\n","\n","epoch  13\n","a: 1.0160429356294758 , b: -1.1339258793286884\n","loss_mean: 8.132055636168612\n","\n","\n","epoch  14\n","a: 1.016038573769674 , b: -1.133874456807889\n","loss_mean: 8.132029046881584\n","\n","\n","epoch  15\n","a: 1.0160366100368121 , b: -1.1338230009405152\n","loss_mean: 8.132002536670957\n","\n","\n","epoch  16\n","a: 1.0160354428209695 , b: -1.1337715357213678\n","loss_mean: 8.131976037547554\n","\n","\n","epoch  17\n","a: 1.0160345401785764 , b: -1.133720069119766\n","loss_mean: 8.131949542011167\n","\n","\n","epoch  18\n","a: 1.0160337254349265 , b: -1.133668603782478\n","loss_mean: 8.131923049234224\n","\n","\n","epoch  19\n","a: 1.0160329399109531 , b: -1.1336171405884896\n","loss_mean: 8.13189655912523\n","\n","\n","epoch  20\n","a: 1.0160321641175447 , b: -1.133565679829653\n","loss_mean: 8.131870071673795\n","\n","\n","epoch  21\n","a: 1.0160313915817707 , b: -1.1335142216028142\n","loss_mean: 8.131843586878585\n","\n","\n","epoch  22\n","a: 1.016030620153772 , b: -1.1334627659400527\n","loss_mean: 8.13181710473919\n","\n","\n","epoch  23\n","a: 1.0160298491195134 , b: -1.1334113128519365\n","loss_mean: 8.131790625255329\n","\n","\n","epoch  24\n","a: 1.0160290782418409 , b: -1.1333598623418892\n","loss_mean: 8.131764148426768\n","\n","\n","epoch  25\n","a: 1.016028307441987 , b: -1.1333084144109615\n","loss_mean: 8.131737674253182\n","\n","\n","epoch  26\n","a: 1.016027536693789 , b: -1.133256969059416\n","loss_mean: 8.131711202734328\n","\n","\n","epoch  27\n","a: 1.0160267659885567 , b: -1.1332055262872536\n","loss_mean: 8.131684733869978\n","\n","\n","epoch  28\n","a: 1.016025995323402 , b: -1.133154086094388\n","loss_mean: 8.13165826765983\n","\n","\n","epoch  29\n","a: 1.016025224697365 , b: -1.1331026484807045\n","loss_mean: 8.13163180410363\n","\n","\n","epoch  30\n","a: 1.0160244541101249 , b: -1.1330512134460784\n","loss_mean: 8.131605343201105\n","\n","\n","epoch  31\n","a: 1.0160236835615744 , b: -1.132999780990382\n","loss_mean: 8.131578884951974\n","\n","\n","epoch  32\n","a: 1.0160229130516762 , b: -1.1329483511134866\n","loss_mean: 8.131552429355999\n","\n","\n","epoch  33\n","a: 1.016022142580417 , b: -1.1328969238152629\n","loss_mean: 8.13152597641291\n","\n","\n","epoch  34\n","a: 1.0160213721477906 , b: -1.1328454990955819\n","loss_mean: 8.131499526122422\n","\n","\n","epoch  35\n","a: 1.0160206017537943 , b: -1.132794076954314\n","loss_mean: 8.131473078484282\n","\n","\n","epoch  36\n","a: 1.0160198313984252 , b: -1.1327426573913304\n","loss_mean: 8.131446633498207\n","\n","\n","epoch  37\n","a: 1.0160190610816815 , b: -1.1326912404065013\n","loss_mean: 8.131420191163963\n","\n","\n","epoch  38\n","a: 1.0160182908035613 , b: -1.1326398259996977\n","loss_mean: 8.131393751481268\n","\n","\n","epoch  39\n","a: 1.0160175205640625 , b: -1.1325884141707903\n","loss_mean: 8.131367314449864\n","\n","\n","epoch  40\n","a: 1.016016750363183 , b: -1.13253700491965\n","loss_mean: 8.131340880069448\n","\n","\n","epoch  41\n","a: 1.0160159802009212 , b: -1.1324855982461473\n","loss_mean: 8.1313144483398\n","\n","\n","epoch  42\n","a: 1.016015210077275 , b: -1.132434194150153\n","loss_mean: 8.131288019260646\n","\n","\n","epoch  43\n","a: 1.0160144399922424 , b: -1.132382792631538\n","loss_mean: 8.131261592831676\n","\n","\n","epoch  44\n","a: 1.0160136699458215 , b: -1.1323313936901729\n","loss_mean: 8.13123516905268\n","\n","\n","epoch  45\n","a: 1.0160128999380107 , b: -1.1322799973259288\n","loss_mean: 8.131208747923388\n","\n","\n","epoch  46\n","a: 1.0160121299688074 , b: -1.1322286035386762\n","loss_mean: 8.131182329443494\n","\n","\n","epoch  47\n","a: 1.0160113600382101 , b: -1.1321772123282858\n","loss_mean: 8.131155913612762\n","\n","\n","epoch  48\n","a: 1.0160105901462169 , b: -1.1321258236946288\n","loss_mean: 8.131129500430928\n","\n","\n","epoch  49\n","a: 1.0160098202928256 , b: -1.1320744376375755\n","loss_mean: 8.131103089897719\n","\n","\n","epoch  50\n","a: 1.0160090504780346 , b: -1.132023054156997\n","loss_mean: 8.131076682012857\n","\n","\n","epoch  51\n","a: 1.0160082807018418 , b: -1.1319716732527643\n","loss_mean: 8.131050276776097\n","\n","\n","epoch  52\n","a: 1.016007510964245 , b: -1.1319202949247478\n","loss_mean: 8.131023874187154\n","\n","\n","epoch  53\n","a: 1.0160067412652427 , b: -1.1318689191728186\n","loss_mean: 8.130997474245785\n","\n","\n","epoch  54\n","a: 1.0160059716048326 , b: -1.1318175459968476\n","loss_mean: 8.130971076951726\n","\n","\n","epoch  55\n","a: 1.0160052019830133 , b: -1.1317661753967054\n","loss_mean: 8.130944682304678\n","\n","\n","epoch  56\n","a: 1.016004432399782 , b: -1.131714807372263\n","loss_mean: 8.130918290304397\n","\n","\n","epoch  57\n","a: 1.0160036628551377 , b: -1.131663441923391\n","loss_mean: 8.13089190095063\n","\n","\n","epoch  58\n","a: 1.016002893349078 , b: -1.1316120790499609\n","loss_mean: 8.130865514243082\n","\n","\n","epoch  59\n","a: 1.0160021238816008 , b: -1.1315607187518428\n","loss_mean: 8.13083913018151\n","\n","\n","epoch  60\n","a: 1.0160013544527045 , b: -1.1315093610289082\n","loss_mean: 8.130812748765637\n","\n","\n","epoch  61\n","a: 1.016000585062387 , b: -1.1314580058810275\n","loss_mean: 8.130786369995217\n","\n","\n","epoch  62\n","a: 1.0159998157106465 , b: -1.131406653308072\n","loss_mean: 8.130759993869964\n","\n","\n","epoch  63\n","a: 1.0159990463974808 , b: -1.1313553033099124\n","loss_mean: 8.130733620389627\n","\n","\n","epoch  64\n","a: 1.0159982771228881 , b: -1.1313039558864195\n","loss_mean: 8.130707249553929\n","\n","\n","epoch  65\n","a: 1.0159975078868666 , b: -1.1312526110374643\n","loss_mean: 8.130680881362597\n","\n","\n","epoch  66\n","a: 1.0159967386894142 , b: -1.1312012687629178\n","loss_mean: 8.130654515815383\n","\n","\n","epoch  67\n","a: 1.0159959695305292 , b: -1.1311499290626508\n","loss_mean: 8.130628152912056\n","\n","\n","epoch  68\n","a: 1.0159952004102093 , b: -1.1310985919365342\n","loss_mean: 8.130601792652259\n","\n","\n","epoch  69\n","a: 1.0159944313284528 , b: -1.131047257384439\n","loss_mean: 8.130575435035796\n","\n","\n","epoch  70\n","a: 1.0159936622852577 , b: -1.130995925406236\n","loss_mean: 8.130549080062398\n","\n","\n","epoch  71\n","a: 1.0159928932806221 , b: -1.1309445960017965\n","loss_mean: 8.130522727731783\n","\n","\n","epoch  72\n","a: 1.0159921243145442 , b: -1.1308932691709912\n","loss_mean: 8.130496378043677\n","\n","\n","epoch  73\n","a: 1.015991355387022 , b: -1.130841944913691\n","loss_mean: 8.13047003099784\n","\n","\n","epoch  74\n","a: 1.0159905864980532 , b: -1.130790623229767\n","loss_mean: 8.130443686593985\n","\n","\n","epoch  75\n","a: 1.0159898176476363 , b: -1.1307393041190903\n","loss_mean: 8.130417344831875\n","\n","\n","epoch  76\n","a: 1.0159890488357692 , b: -1.1306879875815314\n","loss_mean: 8.130391005711225\n","\n","\n","epoch  77\n","a: 1.01598828006245 , b: -1.1306366736169617\n","loss_mean: 8.13036466923177\n","\n","\n","epoch  78\n","a: 1.0159875113276768 , b: -1.1305853622252522\n","loss_mean: 8.130338335393235\n","\n","\n","epoch  79\n","a: 1.0159867426314475 , b: -1.1305340534062738\n","loss_mean: 8.13031200419539\n","\n","\n","epoch  80\n","a: 1.0159859739737604 , b: -1.1304827471598973\n","loss_mean: 8.130285675637932\n","\n","\n","epoch  81\n","a: 1.0159852053546137 , b: -1.130431443485994\n","loss_mean: 8.130259349720632\n","\n","\n","epoch  82\n","a: 1.015984436774005 , b: -1.1303801423844346\n","loss_mean: 8.130233026443193\n","\n","\n","epoch  83\n","a: 1.0159836682319325 , b: -1.1303288438550905\n","loss_mean: 8.130206705805348\n","\n","\n","epoch  84\n","a: 1.0159828997283946 , b: -1.1302775478978326\n","loss_mean: 8.130180387806874\n","\n","\n","epoch  85\n","a: 1.015982131263389 , b: -1.130226254512532\n","loss_mean: 8.13015407244748\n","\n","\n","epoch  86\n","a: 1.0159813628369139 , b: -1.1301749636990595\n","loss_mean: 8.130127759726886\n","\n","\n","epoch  87\n","a: 1.0159805944489675 , b: -1.1301236754572863\n","loss_mean: 8.130101449644856\n","\n","\n","epoch  88\n","a: 1.0159798260995476 , b: -1.1300723897870835\n","loss_mean: 8.130075142201092\n","\n","\n","epoch  89\n","a: 1.0159790577886525 , b: -1.1300211066883221\n","loss_mean: 8.130048837395366\n","\n","\n","epoch  90\n","a: 1.0159782895162799 , b: -1.1299698261608733\n","loss_mean: 8.130022535227393\n","\n","\n","epoch  91\n","a: 1.0159775212824285 , b: -1.129918548204608\n","loss_mean: 8.129996235696911\n","\n","\n","epoch  92\n","a: 1.0159767530870958 , b: -1.1298672728193973\n","loss_mean: 8.129969938803656\n","\n","\n","epoch  93\n","a: 1.01597598493028 , b: -1.1298160000051123\n","loss_mean: 8.129943644547373\n","\n","\n","epoch  94\n","a: 1.0159752168119796 , b: -1.1297647297616242\n","loss_mean: 8.129917352927793\n","\n","\n","epoch  95\n","a: 1.015974448732192 , b: -1.129713462088804\n","loss_mean: 8.129891063944621\n","\n","\n","epoch  96\n","a: 1.0159736806909159 , b: -1.1296621969865228\n","loss_mean: 8.129864777597643\n","\n","\n","epoch  97\n","a: 1.015972912688149 , b: -1.1296109344546519\n","loss_mean: 8.129838493886574\n","\n","\n","epoch  98\n","a: 1.0159721447238892 , b: -1.129559674493062\n","loss_mean: 8.129812212811128\n","\n","\n","epoch  99\n","a: 1.0159713767981349 , b: -1.1295084171016248\n","loss_mean: 8.129785934371078\n","\n","\n"]}]},{"cell_type":"markdown","source":["#Multiple Linear Regression\n"],"metadata":{"id":"pz-rp2pKcIbn"}},{"cell_type":"markdown","source":["input으로 여러개의 입력이 들어가는 Linear Regression"],"metadata":{"id":"GhRs2kbPcLvY"}},{"cell_type":"markdown","source":["**Dataset load**  \n","\n","data link: https://www.kaggle.com/datasets/fayejavad/marketing-linear-multiple-regression  \n","x = [\"youtube\",\"facebook\",\"newspaper\"]  \n","y = [\"sales\"]"],"metadata":{"id":"bt2MeDUY4syB"}},{"cell_type":"code","source":["data_path = \"/content/drive/MyDrive/nlp-open-tutorial/1일차_배포/colab/LR_dataset\"\n","train_file = \"Marketing_Data.csv\"\n","\n","multi_df_data = pd.read_csv(os.path.join(data_path,train_file))\n","print(multi_df_data)\n","\n","x_multi_df = multi_df_data.loc[:, [\"youtube\",\"facebook\",\"newspaper\"]]\n","print(x_multi_df)\n","y_sales = list(multi_df_data.loc[:, \"sales\"])\n","print(y_sales)\n","\n","x_youtube = list(x_multi_df.loc[:, \"youtube\"])\n","print(x_youtube)\n","x_facebook = list(x_multi_df.loc[:, \"facebook\"])\n","print(x_facebook)\n","x_newspaper = list(x_multi_df.loc[:, \"newspaper\"])\n","print(x_newspaper)"],"metadata":{"id":"oijzv-LocMYv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691500651817,"user_tz":-540,"elapsed":905,"user":{"displayName":"Wooseok Kim (Wooseok)","userId":"10829587564796253131"}},"outputId":"7b341b57-3b6d-4214-b38b-f41a1fca73de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["     youtube  facebook  newspaper  sales\n","0      84.72     19.20      48.96  12.60\n","1     351.48     33.96      51.84  25.68\n","2     135.48     20.88      46.32  14.28\n","3     116.64      1.80      36.00  11.52\n","4     318.72     24.00       0.36  20.88\n","..       ...       ...        ...    ...\n","166    45.84      4.44      16.56   9.12\n","167   113.04      5.88       9.72  11.64\n","168   212.40     11.16       7.68  15.36\n","169   340.32     50.40      79.44  30.60\n","170   278.52     10.32      10.44  16.08\n","\n","[171 rows x 4 columns]\n","     youtube  facebook  newspaper\n","0      84.72     19.20      48.96\n","1     351.48     33.96      51.84\n","2     135.48     20.88      46.32\n","3     116.64      1.80      36.00\n","4     318.72     24.00       0.36\n","..       ...       ...        ...\n","166    45.84      4.44      16.56\n","167   113.04      5.88       9.72\n","168   212.40     11.16       7.68\n","169   340.32     50.40      79.44\n","170   278.52     10.32      10.44\n","\n","[171 rows x 3 columns]\n","[12.6, 25.68, 14.28, 11.52, 20.88, 11.4, 15.36, 30.48, 17.64, 12.12, 25.8, 19.92, 20.52, 24.84, 15.48, 10.2, 17.88, 12.72, 27.84, 17.76, 11.64, 13.68, 12.84, 27.12, 25.44, 24.24, 28.44, 6.6, 15.84, 28.56, 22.08, 9.72, 29.04, 18.84, 16.8, 21.6, 11.16, 11.4, 16.08, 22.68, 26.76, 21.96, 14.88, 10.56, 13.2, 20.4, 10.44, 8.28, 17.04, 6.36, 13.2, 14.16, 14.76, 13.56, 16.32, 26.04, 18.24, 14.4, 19.2, 15.48, 20.04, 13.44, 8.76, 23.28, 26.64, 13.8, 20.28, 14.04, 18.6, 30.48, 20.64, 14.04, 28.56, 17.76, 17.64, 24.84, 23.04, 8.64, 10.44, 6.36, 23.76, 16.08, 26.16, 16.92, 19.08, 17.52, 15.12, 14.64, 11.28, 19.08, 7.92, 18.6, 8.4, 13.92, 18.24, 23.64, 12.72, 7.92, 10.56, 29.64, 11.64, 1.92, 15.24, 6.84, 23.52, 12.96, 13.92, 11.4, 24.96, 11.52, 24.84, 13.08, 23.04, 24.12, 12.48, 13.68, 12.36, 15.84, 30.48, 13.08, 12.12, 19.32, 13.92, 19.92, 22.8, 18.72, 3.84, 18.36, 12.12, 8.76, 15.48, 17.28, 15.96, 17.88, 21.6, 14.28, 14.28, 9.6, 14.64, 20.52, 18.0, 10.08, 17.4, 9.12, 14.04, 13.8, 32.4, 24.24, 14.04, 14.16, 15.12, 12.6, 14.64, 10.44, 31.44, 21.12, 27.12, 12.36, 20.76, 19.08, 8.04, 12.96, 11.88, 7.08, 23.52, 20.76, 9.12, 11.64, 15.36, 30.6, 16.08]\n","[84.72, 351.48, 135.48, 116.64, 318.72, 114.84, 348.84, 320.28, 89.64, 51.72, 273.6, 243.0, 212.4, 352.32, 248.28, 30.12, 210.12, 107.64, 287.88, 272.64, 80.28, 239.76, 120.48, 259.68, 219.12, 315.24, 238.68, 8.76, 163.44, 252.96, 252.84, 64.2, 313.56, 287.16, 123.24, 157.32, 82.8, 37.8, 167.16, 284.88, 260.16, 238.92, 131.76, 32.16, 155.28, 256.08, 20.28, 33.0, 144.6, 6.48, 139.2, 91.68, 287.76, 90.36, 82.08, 256.2, 231.84, 91.56, 132.84, 105.96, 131.76, 161.16, 34.32, 261.24, 301.08, 128.88, 195.96, 237.12, 221.88, 347.64, 162.24, 266.88, 355.68, 336.24, 225.48, 285.84, 165.48, 30.0, 108.48, 15.72, 306.48, 270.96, 290.04, 210.84, 251.52, 93.84, 90.12, 167.04, 91.68, 150.84, 23.28, 169.56, 22.56, 268.8, 147.72, 275.4, 104.64, 9.36, 96.24, 264.36, 71.52, 0.84, 318.24, 10.08, 263.76, 44.28, 57.96, 30.72, 328.44, 51.6, 221.88, 88.08, 232.44, 264.6, 125.52, 115.44, 168.36, 288.12, 291.84, 45.6, 53.64, 336.84, 145.2, 237.12, 205.56, 225.36, 4.92, 112.68, 179.76, 14.04, 158.04, 207.0, 102.84, 226.08, 196.2, 140.64, 281.4, 21.48, 248.16, 258.48, 341.16, 60.0, 197.4, 23.52, 202.08, 266.88, 332.28, 298.08, 204.24, 332.04, 198.72, 187.92, 262.2, 67.44, 345.12, 304.56, 246.0, 167.4, 229.32, 343.2, 22.44, 47.4, 90.6, 20.64, 200.16, 179.64, 45.84, 113.04, 212.4, 340.32, 278.52]\n","[19.2, 33.96, 20.88, 1.8, 24.0, 1.68, 4.92, 52.56, 59.28, 32.04, 45.24, 26.76, 40.08, 33.24, 10.08, 30.84, 27.0, 11.88, 49.8, 18.96, 14.04, 3.72, 11.52, 50.04, 55.44, 34.56, 59.28, 33.72, 23.04, 59.52, 35.4, 2.4, 51.24, 18.6, 35.52, 51.36, 11.16, 29.52, 17.4, 33.0, 52.68, 36.72, 17.16, 39.6, 6.84, 29.52, 52.44, 1.92, 34.2, 35.88, 9.24, 32.04, 4.92, 24.36, 53.4, 51.6, 22.08, 33.0, 48.72, 30.6, 57.36, 5.88, 1.8, 40.2, 43.8, 16.8, 37.92, 4.2, 25.2, 50.76, 50.04, 5.16, 43.56, 12.12, 20.64, 41.16, 55.68, 13.2, 0.36, 0.48, 32.28, 9.84, 45.6, 18.48, 24.72, 56.16, 42.0, 17.16, 0.96, 44.28, 19.2, 32.16, 26.04, 2.88, 41.52, 38.76, 14.16, 46.68, 0.0, 58.8, 14.4, 47.52, 3.48, 32.64, 40.2, 46.32, 56.4, 46.8, 34.68, 31.08, 52.68, 20.4, 42.48, 39.84, 6.84, 17.76, 2.28, 8.76, 58.8, 48.36, 30.96, 16.68, 10.08, 27.96, 47.64, 25.32, 13.92, 52.2, 1.56, 44.28, 22.08, 21.72, 42.96, 21.72, 44.16, 17.64, 4.08, 45.12, 6.24, 28.32, 12.72, 13.92, 25.08, 24.12, 8.52, 4.08, 58.68, 36.24, 9.36, 2.76, 12.0, 3.12, 6.48, 6.84, 51.6, 25.56, 54.12, 2.52, 34.44, 16.68, 14.52, 49.32, 12.96, 4.92, 50.4, 42.72, 4.44, 5.88, 11.16, 50.4, 10.32]\n","[48.96, 51.84, 46.32, 36.0, 0.36, 8.88, 10.2, 6.0, 54.84, 42.12, 38.4, 37.92, 46.44, 2.16, 31.68, 51.96, 37.8, 42.84, 22.2, 59.88, 44.16, 41.52, 4.32, 47.52, 70.44, 19.08, 72.0, 49.68, 19.92, 45.24, 11.16, 25.68, 65.64, 32.76, 10.08, 34.68, 1.08, 2.64, 12.24, 13.2, 32.64, 46.44, 38.04, 23.16, 37.56, 15.72, 107.28, 24.84, 17.04, 11.28, 27.72, 26.76, 44.28, 39.0, 42.72, 40.56, 78.84, 19.2, 75.84, 88.08, 61.68, 11.16, 39.6, 70.8, 86.76, 13.08, 63.48, 7.08, 26.4, 61.44, 55.08, 59.76, 121.08, 25.68, 21.48, 6.36, 70.8, 35.64, 27.84, 30.72, 6.6, 67.8, 27.84, 2.88, 12.84, 41.4, 63.24, 30.72, 17.76, 95.04, 26.76, 55.44, 60.48, 18.72, 14.88, 89.04, 31.08, 60.72, 11.04, 3.84, 51.72, 10.44, 51.6, 2.52, 54.12, 78.72, 10.2, 11.16, 71.64, 24.6, 2.04, 15.48, 90.72, 45.48, 41.28, 46.68, 10.8, 10.44, 53.16, 14.28, 24.72, 44.4, 58.44, 17.04, 45.24, 11.4, 6.84, 60.6, 29.16, 54.24, 41.52, 36.84, 59.16, 30.72, 8.88, 6.48, 101.76, 25.92, 23.28, 69.12, 7.68, 22.08, 56.88, 20.4, 15.36, 15.72, 50.16, 24.36, 42.24, 28.44, 21.12, 9.96, 32.88, 35.64, 86.16, 36.0, 23.52, 31.92, 21.84, 4.44, 28.08, 6.96, 7.2, 37.92, 4.32, 7.2, 16.56, 9.72, 7.68, 79.44, 10.44]\n"]}]},{"cell_type":"markdown","source":["**Gradient Descent**\n","\n","hypo(f(x)): ax1 + bx2 + cx3+ d = y  \n","loss(MSE): (f(x) - y) ^ 2 / n\n","\n","loss function을 a,b,c,d에 대해서 편미분   \n","MSE의 편미분: 2 * (f(x) - y)f'(x) / n\n","\n","Gradient Descent 방법을 사용하여 최적의 parameter a,b,c,d를 도출하는 코드 작성"],"metadata":{"id":"9PmAKy6VjbRo"}},{"cell_type":"code","source":["def f(a,b,c,d,x1,x2,x3):\n","  return a * x1 + b * x2 + c * x3 + d\n","\n","def loss(y,y_pred):\n","  return (y_pred - y)**2\n","\n","def ffa(a,b,c,d,x1,x2,x3,y):\n","  return 2 * (a * x1 + b * x2 + c * x3 + d - y) * x1\n","\n","def ffb(a,b,c,d,x1,x2,x3,y):\n","  return 2 * (a * x1 + b * x2 + c * x3 + d - y) * x2\n","\n","def ffc(a,b,c,d,x1,x2,x3,y):\n","  return 2 * (a * x1 + b * x2 + c * x3 + d - y) * x3\n","\n","def ffd(a,b,c,d,x1,x2,x3,y):\n","  return 2 * (a * x1 + b * x2 + c * x3 + d - y)\n","\n","data_num = len(multi_df_data)\n","a = 10\n","b = 3\n","c = 10\n","d = 5\n","lr = 0.00002\n","for e in range(100):\n","  print(\"epoch \",e)\n","  loss_sum = 0\n","  grad_a_sum = 0\n","  grad_b_sum = 0\n","  grad_c_sum = 0\n","  grad_d_sum = 0\n","\n","  print(a,b,c,d)\n","  for i in range(len(multi_df_data)):\n","    y_pred = f(a, b, c, d, x_youtube[i], x_facebook[i], x_newspaper[i])\n","    loss_sum += loss(y_pred, y_sales[i])\n","    grad_a_sum += ffa(a, b, c, d, x_youtube[i], x_facebook[i], x_newspaper[i], y_sales[i])\n","    grad_b_sum += ffb(a, b, c, d, x_youtube[i], x_facebook[i], x_newspaper[i], y_sales[i])\n","    grad_c_sum += ffc(a, b, c, d, x_youtube[i], x_facebook[i], x_newspaper[i], y_sales[i])\n","    grad_d_sum += ffd(a, b, c, d, x_youtube[i], x_facebook[i], x_newspaper[i], y_sales[i])\n","\n","  loss_mean = loss_sum / data_num\n","  a -= lr * (grad_a_sum / data_num)\n","  b -= lr * (grad_b_sum / data_num)\n","  c -= lr * (grad_c_sum / data_num)\n","  d -= lr * (grad_d_sum / data_num)\n","\n","  print(loss_mean)\n","  print(\"\\n\")"],"metadata":{"id":"G3WyFmsAja3-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691500686732,"user_tz":-540,"elapsed":945,"user":{"displayName":"Wooseok Kim (Wooseok)","userId":"10829587564796253131"}},"outputId":"7319fb6c-a98c-4e16-b13c-be2becac44c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch  0\n","10 3 10 5\n","6026525.668435087\n","\n","\n","epoch  1\n","-9.97723263663157 0.41002450863158035 6.520657397894736 4.911851901754386\n","3430642.6895847656\n","\n","\n","epoch  2\n","5.147524276914627 2.1489300629839185 8.652125511401525 4.973733278521439\n","1961158.3538358414\n","\n","\n","epoch  3\n","-6.126444945470823 0.6423040630091572 6.582842108108108 4.922981926225601\n","1128689.7175933495\n","\n","\n","epoch  4\n","2.4459561450050007 1.5852713832027923 7.68982022631579 4.957097249413439\n","656521.7548163107\n","\n","\n","epoch  5\n","-3.9087215539577835 0.6950574864801721 6.425298800392884 4.927564361218839\n","388186.04048690334\n","\n","\n","epoch  6\n","0.9572671716983479 1.1916985747022002 6.960216340253131 4.946051125230826\n","235204.20862342304\n","\n","\n","epoch  7\n","-2.6175078026220278 0.6535709480667065 6.157644083903892 4.928583478883429\n","147541.21715548553\n","\n","\n","epoch  8\n","0.1513342618402609 0.9012623932789394 6.375765891874187 4.938298878892584\n","96899.1029982455\n","\n","\n","epoch  9\n","-1.8530632936306932 0.5654793328291465 5.840786373771968 4.927715778094547\n","67270.95840802278\n","\n","\n","epoch  10\n","-0.27134900628026326 0.6755447757618155 5.885939122508666 4.932531872156599\n","49599.95552989187\n","\n","\n","epoch  11\n","-1.3891440180706869 0.45717472087268146 5.508175679165245 4.925899161180669\n","38759.43381794455\n","\n","\n","epoch  12\n","-0.4799127110417355 0.4923036664367059 5.461215723549493 4.9280005584164694\n","31845.356401239093\n","\n","\n","epoch  13\n","-1.0976208695678693 0.3430804616974753 5.177812273453107 4.9236546908396805\n","27210.803570717664\n","\n","\n","epoch  14\n","-0.5697866797462066 0.33848380389394417 5.084027182194464 4.924272254532477\n","23920.028484411276\n","\n","\n","epoch  15\n","-0.9058564229529942 0.23089161541612363 4.859030773630965 4.921268456935056\n","21439.742450436777\n","\n","\n","epoch  16\n","-0.5947447745159321 0.20626176924495673 4.7436298540169215 4.921094123834286\n","19464.535826536587\n","\n","\n","epoch  17\n","-0.772603859267058 0.12453496538141484 4.556330600085618 4.918894351786811\n","17818.143398634693\n","\n","\n","epoch  18\n","-0.5850220614817976 0.09080689581942064 4.433200960488764 4.918315651606268\n","16397.595343160774\n","\n","\n","epoch  19\n","-0.6743787013229839 0.02583987258123066 4.271536825480333 4.916612130107443\n","15141.618142770725\n","\n","\n","epoch  20\n","-0.5575574574624569 -0.010987422532741785 4.148191860080911 4.915844762642052\n","14012.748438128965\n","\n","\n","epoch  21\n","-0.597752130098411 -0.06451956605784329 4.005017380003697 4.914460190078682\n","12987.201893447844\n","\n","\n","epoch  22\n","-0.5217840801652776 -0.10122353827978992 3.885392567803551 4.9136229643200755\n","12049.128256255744\n","\n","\n","epoch  23\n","-0.5349925375879729 -0.14649417775678508 3.7563670571092778 4.912454064971759\n","11187.347720634763\n","\n","\n","epoch  24\n","-0.48290227648507605 -0.1814088186204464 3.64239876374182 4.911611250482023\n","10393.49143997723\n","\n","\n","epoch  25\n","-0.4816003000921985 -0.22036203990504932 3.5247903643388794 4.910596838616306\n","9660.937058436835\n","\n","\n","epoch  26\n","-0.4437293883483355 -0.252689154972374 3.41730668710406 4.909782092844065\n","8984.194764956901\n","\n","\n","epoch  27\n","-0.434913077029378 -0.2865621904330379 3.3093143959686513 4.908884997562843\n","8358.549008881379\n","\n","\n","epoch  28\n","-0.40574484922182497 -0.31598293352309154 3.2085371682124952 4.908114877353161\n","7779.845628187161\n","\n","\n","epoch  29\n","-0.3933164652072056 -0.34560246930044547 3.108905873849221 4.907311705920429\n","7244.361987862051\n","\n","\n","epoch  30\n","-0.3696803686034806 -0.372058575308301 3.0147329428505176 4.906593291099803\n","6748.724784190573\n","\n","\n","epoch  31\n","-0.3557969891329529 -0.3980091311937644 2.9225342587064334 4.905868625556447\n","6289.855474551531\n","\n","\n","epoch  32\n","-0.33585295816619387 -0.4215800315422698 2.8346976468937735 4.905203814626022\n","5864.931949689926\n","\n","\n","epoch  33\n","-0.32168870750327244 -0.44429994368831605 2.7492046044760228 4.904546916241783\n","5471.359964424871\n","\n","\n","epoch  34\n","-0.3043526083056912 -0.46513403290397326 2.667358604046243 4.903934841567266\n","5106.750616410913\n","\n","\n","epoch  35\n","-0.29052934315077655 -0.4849704420341799 2.5879735223973808 4.903337774358616\n","4768.901734239651\n","\n","\n","epoch  36\n","-0.27514782955171047 -0.5032469045950382 2.5117432755727207 4.90277615514565\n","4455.78192795415\n","\n","\n","epoch  37\n","-0.26197838525422545 -0.5204875098998663 2.4379557958953044 4.9022327127667635\n","4165.516562175899\n","\n","\n","epoch  38\n","-0.24814479762291453 -0.53639537314927 2.3669636276640276 4.9017186084143\n","3896.3752014562087\n","\n","\n","epoch  39\n","-0.23577027407581325 -0.5512869980218111 2.2983258946241785 4.901223696220829\n","3646.760243571089\n","\n","\n","epoch  40\n","-0.2232203060033635 -0.5650138758711859 2.232205153643023 4.900753921534966\n","3415.1965526768267\n","\n","\n","epoch  41\n","-0.21168746107720332 -0.5777735296729303 2.168316775517791 4.90030319687087\n","3200.3219607392834\n","\n","\n","epoch  42\n","-0.2002399464987052 -0.5894998003085454 2.1067186924809262 4.899874546916523\n","3000.878539534997\n","\n","\n","epoch  43\n","-0.1895447430381657 -0.6003214537285578 2.0472173078105413 4.899464206199159\n","2815.7045664739157\n","\n","\n","epoch  44\n","-0.17906797218630494 -0.6102174679577039 1.9898139801387082 4.899073574281607\n","2643.727120994235\n","\n","\n","epoch  45\n","-0.16918000404207723 -0.6192763645791861 1.9343690658251718 4.898700223822568\n","2483.955257440767\n","\n","\n","epoch  46\n","-0.15957248951598316 -0.6275013291361387 1.8808543207520216 4.8983446597477895\n","2335.4737069274915\n","\n","\n","epoch  47\n","-0.15044861137080054 -0.6349568668398208 1.8291628988683486 4.898005234596507\n","2197.4370657120294\n","\n","\n","epoch  48\n","-0.1416280390293333 -0.6416586391018403 1.7792520202977529 4.897681969814865\n","2069.064431653237\n","\n","\n","epoch  49\n","-0.13321990580810603 -0.6476564085931239 1.7310354993323886 4.897373680380135\n","1949.6344537182063\n","\n","\n","epoch  50\n","-0.12511672687704564 -0.6529717737276223 1.6844643707402867 4.897080135005947\n","1838.4807624480097\n","\n","\n","epoch  51\n","-0.11737490239786083 -0.6576450888854392 1.639466084461901 4.896800429960556\n","1734.9877519003583\n","\n","\n","epoch  52\n","-0.10992856214757851 -0.6617002794099649 1.5959900556093027 4.8965342100983555\n","1638.5866859344812\n","\n","\n","epoch  53\n","-0.10280469983652056 -0.6651713911346202 1.5539732482487223 4.896280749023026\n","1548.7521038356333\n","\n","\n","epoch  54\n","-0.09596136842240263 -0.6680827155176728 1.5133658955703178 4.8960396391247825\n","1464.998502225206\n","\n","\n","epoch  55\n","-0.08940931289902466 -0.6704638197014825 1.4741120072399267 4.895810271150497\n","1386.8772719901212\n","\n","\n","epoch  56\n","-0.08312047607513745 -0.6723383267517843 1.4361638801200096 4.89559222403557\n","1313.9738706090648\n","\n","\n","epoch  57\n","-0.07709676469454141 -0.6737324309945353 1.3994710461928335 4.895384970331261\n","1245.9052117670783\n","\n","\n","epoch  58\n","-0.07131831042998364 -0.6746685706128887 1.3639884477289372 4.8951880963207985\n","1182.3172555454998\n","\n","\n","epoch  59\n","-0.06578234488625437 -0.6751702581344406 1.329670159995779 4.895001135174116\n","1122.882783761259\n","\n","\n","epoch  60\n","-0.0604739393419088 -0.6752585179750311 1.2964739864639845 4.894823691127165\n","1067.2993462169004\n","\n","\n","epoch  61\n","-0.05538797933620104 -0.6749546322333132 1.2643578834269138 4.89465534487804\n","1015.287364718383\n","\n","\n","epoch  62\n","-0.05051261472955135 -0.6742781404072884 1.2332825331254853 4.89449572354352\n","966.5883827288881\n","\n","\n","epoch  63\n","-0.045841678984943915 -0.6732484053443726 1.2032092980754832 4.89434444692219\n","920.9634494601564\n","\n","\n","epoch  64\n","-0.04136532628527463 -0.6718834951533778 1.1741016528011303 4.894201166812326\n","878.1916280643039\n","\n","\n","epoch  65\n","-0.037077048516291115 -0.6702010810123893 1.1459240049337112 4.89406553640086\n","838.0686183841948\n","\n","\n","epoch  66\n","-0.03296837646683458 -0.6682178168895848 1.1186424833620634 4.893937232275919\n","800.4054854543975\n","\n","\n","epoch  67\n","-0.02903284265700521 -0.665949858613638 1.0922242511254627 4.893815936909033\n","765.0274856222068\n","\n","\n","epoch  68\n","-0.025262980810856383 -0.6634125241420182 1.0666379313130143 4.893701350899804\n","731.7729827836089\n","\n","\n","epoch  69\n","-0.02165256217750747 -0.6606205976018749 1.0418531996015001 4.893593182877413\n","700.4924478062676\n","\n","\n","epoch  70\n","-0.018194894830106896 -0.657588147333816 1.0178410068470827 4.893491156237913\n","671.047534744478\n","\n","\n","epoch  71\n","-0.014884084125281125 -0.6543287075345884 0.9945733311943139 4.893395003255673\n","643.3102279428916\n","\n","\n","epoch  72\n","-0.011714067264359465 -0.65085518472465 0.9720232871128273 4.893304468721054\n","617.1620545798185\n","\n","\n","epoch  73\n","-0.00867932229238804 -0.6471799694308487 0.9501649690739804 4.893219306445989\n","592.4933576200107\n","\n","\n","epoch  74\n","-0.005774318683541776 -0.6433148919257525 0.9289734976726243 4.893139281162341\n","569.2026245337\n","\n","\n","epoch  75\n","-0.0029939148192664107 -0.6392712936578565 0.9084249163178199 4.893064166393886\n","547.1958674957481\n","\n","\n","epoch  76\n","-0.0003330440728800269 -0.635060010181341 0.888496202973162 4.8929937453834444\n","526.3860511083985\n","\n","\n","epoch  77\n","0.0022130635893351162 -0.6306914191845753 0.8691651979674331 4.892927809749199\n","506.69256399540956\n","\n","\n","epoch  78\n","0.004649062117011772 -0.6261754381767229 0.8504105973951631 4.892866159873963\n","488.0407308961994\n","\n","\n","epoch  79\n","0.006979366976625364 -0.6215215586917653 0.8322118995799186 4.892808604015805\n","470.36136214790804\n","\n","\n","epoch  80\n","0.009208259998027296 -0.6167388517493929 0.814549389120764 4.892754958403616\n","453.59033768261486\n","\n","\n","epoch  81\n","0.011339822842703778 -0.6118359936953804 0.7974040948777357 4.89270504661461\n","437.6682228878391\n","\n","\n","epoch  82\n","0.013377998855301509 -0.6068212755326359 0.7807577696667898 4.892658699513438\n","422.5399138824069\n","\n","\n","epoch  83\n","0.015326557914259567 -0.601702623527764 0.7645928556607993 4.892615754789818\n","408.15430994797237\n","\n","\n","epoch  84\n","0.01718913377544982 -0.5964876102453577 0.748892462489479 4.892576056818056\n","394.4640110302648\n","\n","\n","epoch  85\n","0.0189692064768403 -0.5911834717293583 0.7336403376647099 4.89253945629374\n","381.4250383845112\n","\n","\n","epoch  86\n","0.02067012564238468 -0.5857971190527994 0.7188208445774956 4.892505810056448\n","368.9965765875502\n","\n","\n","epoch  87\n","0.022295102636577187 -0.5803351531325305 0.7044189365316925 4.892474980790316\n","357.14073527581047\n","\n","\n","epoch  88\n","0.023847225761491255 -0.5748038761573556 0.6904201354202352 4.892446836833488\n","345.82232909449925\n","\n","\n","epoch  89\n","0.02532945776214033 -0.5692093046678318 0.6768105085077014 4.892421251922066\n","335.0086744597858\n","\n","\n","epoch  90\n","0.02674464628419104 -0.5635571805344796 0.6635766481714231 4.89239810499903\n","324.6694018432679\n","\n","\n","epoch  91\n","0.02809552425527758 -0.5578529826904629 0.6507056508924215 4.892377279989419\n","314.776282387239\n","\n","\n","epoch  92\n","0.029384717519413822 -0.5521019375036562 0.638185098227121 4.892358665615398\n","305.30306775086524\n","\n","\n","epoch  93\n","0.030614746706442156 -0.5463090294097461 0.6260030376508052 4.8923421551952755\n","296.225342171943\n","\n","\n","epoch  94\n","0.03178803313754582 -0.5404790106169867 0.6141479648053433 4.892327646467987\n","287.5203858069443\n","\n","\n","epoch  95\n","0.0329069014087546 -0.5346164108057775 0.6026088059475639 4.892315041411298\n","279.1670484841132\n","\n","\n","epoch  96\n","0.0339735841965496 -0.5287255461565882 0.5913749014540911 4.892304246077102\n","271.1456330708807\n","\n","\n","epoch  97\n","0.03499022512755032 -0.5228105282339854 0.5804359896918097 4.892295170425736\n","263.4377877182499\n","\n","\n","epoch  98\n","0.03595888284927003 -0.5168752723554805 0.5697821917279714 4.892287728172452\n","256.02640630147727\n","\n","\n","epoch  99\n","0.03688153395310282 -0.5109235057489356 0.5594039964798428 4.892281836635712\n","248.89553642869356\n","\n","\n"]}]},{"cell_type":"markdown","source":["#Multiple Logisitc Regression"],"metadata":{"id":"opLA1yk-GrRt"}},{"cell_type":"markdown","source":["**Dataset load**  \n","\n","data link: https://www.kaggle.com/datasets/dragonheir/logistic-regression  \n","x = [\"Age\",\"EstimatedSalary\"]  \n","y = [\"Purchased\"]  "],"metadata":{"id":"rJLTQD5vG-ag"}},{"cell_type":"code","source":["data_path = \"/content/drive/MyDrive/nlp-open-tutorial/1일차_배포/colab/LR_dataset\"\n","train_file = \"Social_Network_Ads.csv\"\n","\n","multi_df_data = pd.read_csv(os.path.join(data_path,train_file))\n","print(multi_df_data)\n","\n","x_multi_df = multi_df_data.loc[:,  [\"Age\",\"EstimatedSalary\"]]\n","print(x_multi_df)\n","y_sales = list(multi_df_data.loc[:, \"Purchased\"])\n","print(y_sales)\n","\n","x_age = list(x_multi_df.loc[:, \"Age\"])\n","print(x_age)\n","x_es = list(x_multi_df.loc[:, \"EstimatedSalary\"])\n","print(x_es)"],"metadata":{"id":"dC7kAZwoGuGg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691502181650,"user_tz":-540,"elapsed":560,"user":{"displayName":"Wooseok Kim (Wooseok)","userId":"10829587564796253131"}},"outputId":"3e0b945f-8430-4db9-f864-55c7078606b5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["      User ID  Gender  Age  EstimatedSalary  Purchased\n","0    15624510    Male   19            19000          0\n","1    15810944    Male   35            20000          0\n","2    15668575  Female   26            43000          0\n","3    15603246  Female   27            57000          0\n","4    15804002    Male   19            76000          0\n","..        ...     ...  ...              ...        ...\n","395  15691863  Female   46            41000          1\n","396  15706071    Male   51            23000          1\n","397  15654296  Female   50            20000          1\n","398  15755018    Male   36            33000          0\n","399  15594041  Female   49            36000          1\n","\n","[400 rows x 5 columns]\n","     Age  EstimatedSalary\n","0     19            19000\n","1     35            20000\n","2     26            43000\n","3     27            57000\n","4     19            76000\n","..   ...              ...\n","395   46            41000\n","396   51            23000\n","397   50            20000\n","398   36            33000\n","399   49            36000\n","\n","[400 rows x 2 columns]\n","[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1]\n","[19, 35, 26, 27, 19, 27, 27, 32, 25, 35, 26, 26, 20, 32, 18, 29, 47, 45, 46, 48, 45, 47, 48, 45, 46, 47, 49, 47, 29, 31, 31, 27, 21, 28, 27, 35, 33, 30, 26, 27, 27, 33, 35, 30, 28, 23, 25, 27, 30, 31, 24, 18, 29, 35, 27, 24, 23, 28, 22, 32, 27, 25, 23, 32, 59, 24, 24, 23, 22, 31, 25, 24, 20, 33, 32, 34, 18, 22, 28, 26, 30, 39, 20, 35, 30, 31, 24, 28, 26, 35, 22, 30, 26, 29, 29, 35, 35, 28, 35, 28, 27, 28, 32, 33, 19, 21, 26, 27, 26, 38, 39, 37, 38, 37, 42, 40, 35, 36, 40, 41, 36, 37, 40, 35, 41, 39, 42, 26, 30, 26, 31, 33, 30, 21, 28, 23, 20, 30, 28, 19, 19, 18, 35, 30, 34, 24, 27, 41, 29, 20, 26, 41, 31, 36, 40, 31, 46, 29, 26, 32, 32, 25, 37, 35, 33, 18, 22, 35, 29, 29, 21, 34, 26, 34, 34, 23, 35, 25, 24, 31, 26, 31, 32, 33, 33, 31, 20, 33, 35, 28, 24, 19, 29, 19, 28, 34, 30, 20, 26, 35, 35, 49, 39, 41, 58, 47, 55, 52, 40, 46, 48, 52, 59, 35, 47, 60, 49, 40, 46, 59, 41, 35, 37, 60, 35, 37, 36, 56, 40, 42, 35, 39, 40, 49, 38, 46, 40, 37, 46, 53, 42, 38, 50, 56, 41, 51, 35, 57, 41, 35, 44, 37, 48, 37, 50, 52, 41, 40, 58, 45, 35, 36, 55, 35, 48, 42, 40, 37, 47, 40, 43, 59, 60, 39, 57, 57, 38, 49, 52, 50, 59, 35, 37, 52, 48, 37, 37, 48, 41, 37, 39, 49, 55, 37, 35, 36, 42, 43, 45, 46, 58, 48, 37, 37, 40, 42, 51, 47, 36, 38, 42, 39, 38, 49, 39, 39, 54, 35, 45, 36, 52, 53, 41, 48, 48, 41, 41, 42, 36, 47, 38, 48, 42, 40, 57, 36, 58, 35, 38, 39, 53, 35, 38, 47, 47, 41, 53, 54, 39, 38, 38, 37, 42, 37, 36, 60, 54, 41, 40, 42, 43, 53, 47, 42, 42, 59, 58, 46, 38, 54, 60, 60, 39, 59, 37, 46, 46, 42, 41, 58, 42, 48, 44, 49, 57, 56, 49, 39, 47, 48, 48, 47, 45, 60, 39, 46, 51, 50, 36, 49]\n","[19000, 20000, 43000, 57000, 76000, 58000, 84000, 150000, 33000, 65000, 80000, 52000, 86000, 18000, 82000, 80000, 25000, 26000, 28000, 29000, 22000, 49000, 41000, 22000, 23000, 20000, 28000, 30000, 43000, 18000, 74000, 137000, 16000, 44000, 90000, 27000, 28000, 49000, 72000, 31000, 17000, 51000, 108000, 15000, 84000, 20000, 79000, 54000, 135000, 89000, 32000, 44000, 83000, 23000, 58000, 55000, 48000, 79000, 18000, 117000, 20000, 87000, 66000, 120000, 83000, 58000, 19000, 82000, 63000, 68000, 80000, 27000, 23000, 113000, 18000, 112000, 52000, 27000, 87000, 17000, 80000, 42000, 49000, 88000, 62000, 118000, 55000, 85000, 81000, 50000, 81000, 116000, 15000, 28000, 83000, 44000, 25000, 123000, 73000, 37000, 88000, 59000, 86000, 149000, 21000, 72000, 35000, 89000, 86000, 80000, 71000, 71000, 61000, 55000, 80000, 57000, 75000, 52000, 59000, 59000, 75000, 72000, 75000, 53000, 51000, 61000, 65000, 32000, 17000, 84000, 58000, 31000, 87000, 68000, 55000, 63000, 82000, 107000, 59000, 25000, 85000, 68000, 59000, 89000, 25000, 89000, 96000, 30000, 61000, 74000, 15000, 45000, 76000, 50000, 47000, 15000, 59000, 75000, 30000, 135000, 100000, 90000, 33000, 38000, 69000, 86000, 55000, 71000, 148000, 47000, 88000, 115000, 118000, 43000, 72000, 28000, 47000, 22000, 23000, 34000, 16000, 71000, 117000, 43000, 60000, 66000, 82000, 41000, 72000, 32000, 84000, 26000, 43000, 70000, 89000, 43000, 79000, 36000, 80000, 22000, 39000, 74000, 134000, 71000, 101000, 47000, 130000, 114000, 142000, 22000, 96000, 150000, 42000, 58000, 43000, 108000, 65000, 78000, 96000, 143000, 80000, 91000, 144000, 102000, 60000, 53000, 126000, 133000, 72000, 80000, 147000, 42000, 107000, 86000, 112000, 79000, 57000, 80000, 82000, 143000, 149000, 59000, 88000, 104000, 72000, 146000, 50000, 122000, 52000, 97000, 39000, 52000, 134000, 146000, 44000, 90000, 72000, 57000, 95000, 131000, 77000, 144000, 125000, 72000, 90000, 108000, 75000, 74000, 144000, 61000, 133000, 76000, 42000, 106000, 26000, 74000, 71000, 88000, 38000, 36000, 88000, 61000, 70000, 21000, 141000, 93000, 62000, 138000, 79000, 78000, 134000, 89000, 39000, 77000, 57000, 63000, 73000, 112000, 79000, 117000, 38000, 74000, 137000, 79000, 60000, 54000, 134000, 113000, 125000, 50000, 70000, 96000, 50000, 141000, 79000, 75000, 104000, 55000, 32000, 60000, 138000, 82000, 52000, 30000, 131000, 60000, 72000, 75000, 118000, 107000, 51000, 119000, 65000, 65000, 60000, 54000, 144000, 79000, 55000, 122000, 104000, 75000, 65000, 51000, 105000, 63000, 72000, 108000, 77000, 61000, 113000, 75000, 90000, 57000, 99000, 34000, 70000, 72000, 71000, 54000, 129000, 34000, 50000, 79000, 104000, 29000, 47000, 88000, 71000, 26000, 46000, 83000, 73000, 130000, 80000, 32000, 74000, 53000, 87000, 23000, 64000, 33000, 139000, 28000, 33000, 60000, 39000, 71000, 34000, 35000, 33000, 23000, 45000, 42000, 59000, 41000, 23000, 20000, 33000, 36000]\n"]}]},{"cell_type":"markdown","source":["**Gradient Desscent**\n","\n","hypo(f(x)): 1 / 1 + e ^ -(a * x1 + b * x2 + c)  \n","loss: -1/n * (y * log(y_pred) + (1-y) + log(1 - y_pred))\n","\n","loss function을 a,b,c에 대해서 편미분  \n","loss의 편미분: (f(x) - y)x / n\n","\n","Gradient Descent 방법을 사용하여 최적의 parameter a,b,c를 도출하는 코드 작성\n","\n","* math.exp, math.log2 사용  "],"metadata":{"id":"AhqO4EodLlbq"}},{"cell_type":"code","source":["import math\n","\n","def f(a,b,c,x1,x2):\n","  return 1 / (1 + np.exp(-(a * x1 + b * x2 + c)))\n","\n","def loss(y,y_pred):\n","  #print(y,y_pred)\n","  return -(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n","\n","def ff_a(a,b,c,x1,x2, y):\n","  return (f(a, b, c, x1, x2) - y) * x1\n","\n","def ff_b(a,b,c,x1,x2, y):\n","  return (f(a, b, c, x1, x2) - y) * x2\n","\n","def ff_c(a,b,c,x1,x2, y):\n","  return f(a, b, c, x1, x2) - y\n","\n","data_num = len(multi_df_data)\n","a = 1\n","b = 2\n","c = 3\n","lr = 0.02\n","for e in range(100):\n","  print(\"epoch \",e)\n","  loss_sum = 0\n","  grad_a_sum = 0\n","  grad_b_sum = 0\n","  grad_c_sum = 0\n","\n","  print(a, b, c)\n","  for i in range(len(multi_df_data)):\n","    y_pred = f(a, b, c, x_age[i], x_es[i])\n","    loss_sum += loss(y_sales[i], y_pred)\n","    grad_a_sum += ff_a(a, b, c, x_age[i], x_es[i], y_sales[i])\n","    grad_b_sum += ff_b(a, b, c, x_age[i], x_es[i], y_sales[i])\n","    grad_c_sum += ff_c(a, b, c, x_age[i], x_es[i], y_sales[i])\n","\n","  loss_mean = loss_sum / data_num\n","  a -= lr * (grad_a_sum / data_num)\n","  b -= lr * (grad_b_sum / data_num)\n","  c -= lr * (grad_c_sum / data_num)\n","  print(loss_mean)\n","  print(\"\\n\")"],"metadata":{"id":"PJbWrtDoLkRB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691503050013,"user_tz":-540,"elapsed":1702,"user":{"displayName":"Wooseok Kim (Wooseok)","userId":"10829587564796253131"}},"outputId":"75e9ecc1-6a8d-4855-ffe2-6c26562cf15a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch  0\n","1 2 3\n","nan\n","\n","\n","epoch  1\n","0.5786 -776.0 2.98715\n","nan\n","\n","\n","epoch  2\n","0.9103000000000001 -159.14999999999998 2.9943000000000004\n","nan\n","\n","\n","epoch  3\n","1.2420000000000002 457.70000000000005 3.0014500000000006\n","nan\n","\n","\n","epoch  4\n","0.8206000000000002 -320.29999999999995 2.988600000000001\n","nan\n","\n","\n","epoch  5\n","1.1523000000000003 296.55000000000007 2.995750000000001\n","nan\n","\n","\n","epoch  6\n","0.7309000000000003 -481.44999999999993 2.982900000000001\n","nan\n","\n","\n","epoch  7\n","1.0626000000000004 135.4000000000001 2.9900500000000014\n","nan\n","\n","\n","epoch  8\n","0.6412000000000004 -642.5999999999999 2.9772000000000016\n","nan\n","\n","\n","epoch  9\n","0.9729000000000005 -25.749999999999886 2.984350000000002\n","nan\n","\n","\n","epoch  10\n","1.3046000000000006 591.1000000000001 2.991500000000002\n","nan\n","\n","\n","epoch  11\n","0.8832000000000007 -186.89999999999986 2.9786500000000022\n","nan\n","\n","\n","epoch  12\n","1.2149000000000008 429.95000000000016 2.9858000000000025\n","nan\n","\n","\n","epoch  13\n","0.7935000000000008 -348.04999999999984 2.9729500000000026\n","nan\n","\n","\n","epoch  14\n","1.1252000000000009 268.8000000000002 2.980100000000003\n","nan\n","\n","\n","epoch  15\n","0.7038000000000009 -509.1999999999998 2.967250000000003\n","nan\n","\n","\n","epoch  16\n","1.035500000000001 107.6500000000002 2.9744000000000033\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-29-980d06e70a3f>:8: RuntimeWarning: divide by zero encountered in log\n","  return -(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n","<ipython-input-29-980d06e70a3f>:8: RuntimeWarning: invalid value encountered in double_scalars\n","  return -(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n","<ipython-input-29-980d06e70a3f>:4: RuntimeWarning: overflow encountered in exp\n","  return 1 / (1 + np.exp(-(a * x1 + b * x2 + c)))\n"]},{"output_type":"stream","name":"stdout","text":["nan\n","\n","\n","epoch  17\n","0.614100000000001 -670.3499999999998 2.9615500000000035\n","nan\n","\n","\n","epoch  18\n","0.9458000000000011 -53.49999999999977 2.9687000000000037\n","nan\n","\n","\n","epoch  19\n","1.2775000000000012 563.3500000000003 2.975850000000004\n","nan\n","\n","\n","epoch  20\n","0.8561000000000012 -214.64999999999975 2.963000000000004\n","nan\n","\n","\n","epoch  21\n","1.1878000000000013 402.2000000000003 2.9701500000000043\n","nan\n","\n","\n","epoch  22\n","0.7664000000000013 -375.7999999999997 2.9573000000000045\n","nan\n","\n","\n","epoch  23\n","1.0981000000000014 241.0500000000003 2.9644500000000047\n","nan\n","\n","\n","epoch  24\n","0.6767000000000014 -536.9499999999997 2.951600000000005\n","nan\n","\n","\n","epoch  25\n","1.0084000000000015 79.90000000000032 2.958750000000005\n","nan\n","\n","\n","epoch  26\n","0.5870000000000015 -698.0999999999997 2.9459000000000053\n","nan\n","\n","\n","epoch  27\n","0.9187000000000016 -81.24999999999966 2.9530500000000055\n","nan\n","\n","\n","epoch  28\n","1.2504000000000017 535.6000000000004 2.9602000000000057\n","nan\n","\n","\n","epoch  29\n","0.8290000000000017 -242.39999999999964 2.947350000000006\n","nan\n","\n","\n","epoch  30\n","1.1607000000000018 374.4500000000004 2.954500000000006\n","nan\n","\n","\n","epoch  31\n","0.7393000000000018 -403.5499999999996 2.9416500000000063\n","nan\n","\n","\n","epoch  32\n","1.071000000000002 213.3000000000004 2.9488000000000065\n","nan\n","\n","\n","epoch  33\n","0.649600000000002 -564.6999999999996 2.9359500000000067\n","nan\n","\n","\n","epoch  34\n","0.9813000000000021 52.15000000000043 2.943100000000007\n","nan\n","\n","\n","epoch  35\n","0.5599000000000021 -725.8499999999996 2.930250000000007\n","nan\n","\n","\n","epoch  36\n","0.8916000000000022 -108.99999999999955 2.9374000000000073\n","nan\n","\n","\n","epoch  37\n","1.2233000000000023 507.8500000000005 2.9445500000000076\n","nan\n","\n","\n","epoch  38\n","0.8019000000000023 -270.1499999999995 2.9317000000000077\n","nan\n","\n","\n","epoch  39\n","1.1336000000000024 346.7000000000005 2.938850000000008\n","nan\n","\n","\n","epoch  40\n","0.7122000000000024 -431.2999999999995 2.926000000000008\n","nan\n","\n","\n","epoch  41\n","1.0439000000000025 185.55000000000052 2.9331500000000084\n","nan\n","\n","\n","epoch  42\n","0.6225000000000025 -592.4499999999995 2.9203000000000086\n","nan\n","\n","\n","epoch  43\n","0.9542000000000026 24.400000000000546 2.9274500000000088\n","nan\n","\n","\n","epoch  44\n","0.5328000000000026 -753.5999999999995 2.914600000000009\n","nan\n","\n","\n","epoch  45\n","0.8645000000000027 -136.74999999999943 2.921750000000009\n","nan\n","\n","\n","epoch  46\n","1.1962000000000028 480.1000000000006 2.9289000000000094\n","nan\n","\n","\n","epoch  47\n","0.7748000000000028 -297.8999999999994 2.9160500000000096\n","nan\n","\n","\n","epoch  48\n","1.106500000000003 318.9500000000006 2.92320000000001\n","nan\n","\n","\n","epoch  49\n","0.6851000000000029 -459.0499999999994 2.91035000000001\n","nan\n","\n","\n","epoch  50\n","1.016800000000003 157.80000000000064 2.91750000000001\n","nan\n","\n","\n","epoch  51\n","0.595400000000003 -620.1999999999994 2.9046500000000104\n","nan\n","\n","\n","epoch  52\n","0.9271000000000031 -3.3499999999993406 2.9118000000000106\n","nan\n","\n","\n","epoch  53\n","1.2588000000000032 613.5000000000007 2.918950000000011\n","nan\n","\n","\n","epoch  54\n","0.8374000000000033 -164.49999999999932 2.906100000000011\n","nan\n","\n","\n","epoch  55\n","1.1691000000000034 452.3500000000007 2.913250000000011\n","nan\n","\n","\n","epoch  56\n","0.7477000000000034 -325.6499999999993 2.9004000000000114\n","nan\n","\n","\n","epoch  57\n","1.0794000000000035 291.2000000000007 2.9075500000000116\n","nan\n","\n","\n","epoch  58\n","0.6580000000000035 -486.7999999999993 2.894700000000012\n","nan\n","\n","\n","epoch  59\n","0.9897000000000036 130.05000000000075 2.901850000000012\n","nan\n","\n","\n","epoch  60\n","0.5683000000000036 -647.9499999999992 2.8890000000000122\n","nan\n","\n","\n","epoch  61\n","0.9000000000000037 -31.099999999999227 2.8961500000000124\n","nan\n","\n","\n","epoch  62\n","1.2317000000000038 585.7500000000008 2.9033000000000126\n","nan\n","\n","\n","epoch  63\n","0.8103000000000038 -192.2499999999992 2.890450000000013\n","nan\n","\n","\n","epoch  64\n","1.142000000000004 424.6000000000008 2.897600000000013\n","nan\n","\n","\n","epoch  65\n","0.7206000000000039 -353.3999999999992 2.8847500000000132\n","nan\n","\n","\n","epoch  66\n","1.052300000000004 263.45000000000084 2.8919000000000135\n","nan\n","\n","\n","epoch  67\n","0.630900000000004 -514.5499999999992 2.8790500000000137\n","nan\n","\n","\n","epoch  68\n","0.9626000000000041 102.30000000000086 2.886200000000014\n","nan\n","\n","\n","epoch  69\n","0.5412000000000041 -675.6999999999991 2.873350000000014\n","nan\n","\n","\n","epoch  70\n","0.8729000000000042 -58.84999999999911 2.8805000000000143\n","nan\n","\n","\n","epoch  71\n","1.2046000000000043 558.0000000000009 2.8876500000000145\n","nan\n","\n","\n","epoch  72\n","0.7832000000000043 -219.9999999999991 2.8748000000000147\n","nan\n","\n","\n","epoch  73\n","1.1149000000000044 396.85000000000093 2.881950000000015\n","nan\n","\n","\n","epoch  74\n","0.6935000000000044 -381.14999999999907 2.869100000000015\n","nan\n","\n","\n","epoch  75\n","1.0252000000000046 235.70000000000095 2.8762500000000153\n","nan\n","\n","\n","epoch  76\n","0.6038000000000046 -542.299999999999 2.8634000000000155\n","nan\n","\n","\n","epoch  77\n","0.9355000000000047 74.55000000000098 2.8705500000000157\n","nan\n","\n","\n","epoch  78\n","0.5141000000000047 -703.449999999999 2.857700000000016\n","nan\n","\n","\n","epoch  79\n","0.8458000000000048 -86.599999999999 2.864850000000016\n","nan\n","\n","\n","epoch  80\n","1.1775000000000049 530.250000000001 2.8720000000000163\n","nan\n","\n","\n","epoch  81\n","0.7561000000000049 -247.74999999999898 2.8591500000000165\n","nan\n","\n","\n","epoch  82\n","1.087800000000005 369.10000000000105 2.8663000000000167\n","nan\n","\n","\n","epoch  83\n","0.666400000000005 -408.89999999999895 2.853450000000017\n","nan\n","\n","\n","epoch  84\n","0.9981000000000051 207.95000000000107 2.860600000000017\n","nan\n","\n","\n","epoch  85\n","0.5767000000000051 -570.0499999999989 2.8477500000000173\n","nan\n","\n","\n","epoch  86\n","0.9084000000000052 46.80000000000109 2.8549000000000175\n","nan\n","\n","\n","epoch  87\n","0.4870000000000052 -731.1999999999989 2.8420500000000177\n","nan\n","\n","\n","epoch  88\n","0.8187000000000053 -114.34999999999889 2.849200000000018\n","nan\n","\n","\n","epoch  89\n","1.1504000000000054 502.50000000000114 2.856350000000018\n","nan\n","\n","\n","epoch  90\n","0.7290000000000054 -275.49999999999886 2.8435000000000183\n","nan\n","\n","\n","epoch  91\n","1.0607000000000055 341.35000000000116 2.8506500000000186\n","nan\n","\n","\n","epoch  92\n","0.6393000000000055 -436.64999999999884 2.8378000000000188\n","nan\n","\n","\n","epoch  93\n","0.9710000000000056 180.20000000000118 2.844950000000019\n","nan\n","\n","\n","epoch  94\n","0.5496000000000056 -597.7999999999988 2.832100000000019\n","nan\n","\n","\n","epoch  95\n","0.8813000000000057 19.050000000001205 2.8392500000000194\n","nan\n","\n","\n","epoch  96\n","0.45990000000000575 -758.9499999999988 2.8264000000000196\n","nan\n","\n","\n","epoch  97\n","0.7916000000000059 -142.09999999999877 2.8335500000000198\n","nan\n","\n","\n","epoch  98\n","1.123300000000006 474.75000000000125 2.84070000000002\n","nan\n","\n","\n","epoch  99\n","0.701900000000006 -303.24999999999875 2.82785000000002\n","nan\n","\n","\n"]}]}]}