{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"d2a9d2297aa84dd683f3f6bb0dbc230d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cb3090740af944b88c4f78bcc73c8dcb","IPY_MODEL_b1dde845447c4720a68a65c92de3756b","IPY_MODEL_434324aee8c64e69a2461aac2cb01615"],"layout":"IPY_MODEL_f110a1a42d8143c9ad5ff492ec2d9503"}},"cb3090740af944b88c4f78bcc73c8dcb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee1da2c558064178a410f87377e987a6","placeholder":"​","style":"IPY_MODEL_83d5c2ba42df4f8e90e6f0e54a7512f5","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"b1dde845447c4720a68a65c92de3756b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e6245e939794bc582d1e81f2d88c140","max":213450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b1ad802ff5df4a9e8b286fb6def4bb22","value":213450}},"434324aee8c64e69a2461aac2cb01615":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8350e6b79f96441b9aae5d8468036594","placeholder":"​","style":"IPY_MODEL_70eb0f05b6754a7ea674437f37571099","value":" 213k/213k [00:00&lt;00:00, 1.89MB/s]"}},"f110a1a42d8143c9ad5ff492ec2d9503":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee1da2c558064178a410f87377e987a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83d5c2ba42df4f8e90e6f0e54a7512f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5e6245e939794bc582d1e81f2d88c140":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1ad802ff5df4a9e8b286fb6def4bb22":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8350e6b79f96441b9aae5d8468036594":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70eb0f05b6754a7ea674437f37571099":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c3e9a1d6e29430db997e745ba8ed908":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_21e6d4f38e86403180dbd41ab9256bd3","IPY_MODEL_ff5fb30e50f6497bafb1e5103c60152b","IPY_MODEL_58625762c81d4b269a24f1e7dc8f769e"],"layout":"IPY_MODEL_d2a4f0e1c30748c4809468134ce52c63"}},"21e6d4f38e86403180dbd41ab9256bd3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5193eb57c954812ad500df2ec6d344d","placeholder":"​","style":"IPY_MODEL_20b47cb8d136402385c120f01eaa13a4","value":"Downloading (…)okenizer_config.json: 100%"}},"ff5fb30e50f6497bafb1e5103c60152b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9461633fec44b108221f67ff27959b3","max":29,"min":0,"orientation":"horizontal","style":"IPY_MODEL_30edbe6000e44ed9a3c215e86a33694e","value":29}},"58625762c81d4b269a24f1e7dc8f769e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fa83885400a4794883490a5c5ff9042","placeholder":"​","style":"IPY_MODEL_7f75b9d9b2b0414bbf8c0d2e77f75c1e","value":" 29.0/29.0 [00:00&lt;00:00, 706B/s]"}},"d2a4f0e1c30748c4809468134ce52c63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5193eb57c954812ad500df2ec6d344d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20b47cb8d136402385c120f01eaa13a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9461633fec44b108221f67ff27959b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30edbe6000e44ed9a3c215e86a33694e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8fa83885400a4794883490a5c5ff9042":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f75b9d9b2b0414bbf8c0d2e77f75c1e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"366cfb3e5aba4b498ea05c9bab08b712":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b8b26ea308d141f5b4daa563804c9135","IPY_MODEL_b3a04e4b8fad459099304f1c43ec3607","IPY_MODEL_07bb5987f3c342ce993745d45b9ab861"],"layout":"IPY_MODEL_7b8d5cbb61454d3599c2a7ed9a5c140f"}},"b8b26ea308d141f5b4daa563804c9135":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c95d69c8cff54bd3a7cc4d20d797610c","placeholder":"​","style":"IPY_MODEL_dc478a75b972446a9397b23c88072dc3","value":"Downloading (…)lve/main/config.json: 100%"}},"b3a04e4b8fad459099304f1c43ec3607":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_da86cc95fa09436399590aca300b3348","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_69eb3f343a714aa5a7713a4df867de92","value":570}},"07bb5987f3c342ce993745d45b9ab861":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a843d6721a143669b7a9a9c4c52e1e5","placeholder":"​","style":"IPY_MODEL_8be99872a8ad42ec992063e7bf60543c","value":" 570/570 [00:00&lt;00:00, 13.4kB/s]"}},"7b8d5cbb61454d3599c2a7ed9a5c140f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c95d69c8cff54bd3a7cc4d20d797610c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc478a75b972446a9397b23c88072dc3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da86cc95fa09436399590aca300b3348":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69eb3f343a714aa5a7713a4df867de92":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4a843d6721a143669b7a9a9c4c52e1e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8be99872a8ad42ec992063e7bf60543c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"4Vy_G2wCjua9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692721374395,"user_tz":-540,"elapsed":15878,"user":{"displayName":"Wooseok Kim (Wooseok)","userId":"10829587564796253131"}},"outputId":"09622007-c7a5-486a-e73e-023368f69377"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"id":"X2Eq1SjUWGER","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692721391052,"user_tz":-540,"elapsed":14064,"user":{"displayName":"Wooseok Kim (Wooseok)","userId":"10829587564796253131"}},"outputId":"a2a7e0b3-11bf-4216-f99f-53c3e272d64a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.32.0-py3-none-any.whl (7.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.2 tokenizers-0.13.3 transformers-4.32.0\n"]}]},{"cell_type":"markdown","source":["# Spam SNS classification"],"metadata":{"id":"RjVOZjEU2pan"}},{"cell_type":"markdown","source":["메일(텍스트)이 spam 메일인지 아닌지를 판별하는 문장 분류 태스크  \n","dataset: https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset  \n","4000개까지 train으로 사용  \n","\n","#Dataset 구축  \n","dataset에서는 __ getitem __을 통해 한개의 데이터를 모델의 입력형태에 맞추어 반환한다.  \n","이번 코드에서는 자연어 문장을 모델에 입력하기 위해 tokenization과 vocab dictionary에 따른 index로의 변환을 진행한다.  \n","또한 label의 ham/spam에 따라 0/1을 label로 변환한다.  \n","\n","주요 class, method:  \n","torchtext.data.utils.get_tokenizer: torchtext에서 제공하는 tokenizer 문법에 따른 tokenization을 수행하는 class 반환  \n","torchtext.vocab.build_vocab_from_iterator:  내 학습데이터에 대한 모든 단어를 입력하면 각 단어에 한개씩 index를 부여한 vocab dictionary 반환  \n","**huggingface.tokenizer:** 사전에 학습된 tokenization을 불러오는 huggingface class  \n","https://huggingface.co/docs/transformers/main_classes/tokenizer\n"],"metadata":{"id":"Hu1IWE_L2xM3"}},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","\n","from transformers import AutoTokenizer,BertTokenizer\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","\n","#dataset load\n","data_path = \"/content/drive/MyDrive/nlp-open-tutorial/4일차_배포/dataset/spam.csv\"\n","data_df = pd.read_csv(data_path, encoding = \"ISO-8859-1\")\n","\n","#train test split\n","data_df = data_df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1)\n","train_df = data_df.loc[:4000,:].reset_index()\n","test_df = data_df.loc[4000:,:].reset_index()\n","\n","#tokenizer load\n","# tokenizer = get_tokenizer(\"basic_english\")\n","\n","#build vocab dictionary\n","# vocab_dict = build_vocab_from_iterator(list(map(tokenizer, data_df)))\n","\n","#huggingface tokenizer load\n","tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n","\n","class myDataset(Dataset):\n","  def __init__(self, df, tokenizer) -> None:\n","      super().__init__()\n","      self.df = df\n","      self.tokenizer = tokenizer\n","\n","  def __len__(self):\n","      return len(self.df)\n","\n","  def __getitem__(self, index):\n","      data = self.df.loc[index, \"v2\"]\n","      target = self.df.loc[index, \"v1\"]\n","\n","      #data tokenization\n","      data = self.tokenizer(data, max_length = 100, padding=\"max_length\", truncation=True)['input_ids']\n","\n","      #labeling\n","      label = 1 if target==\"spam\" else 0\n","\n","      return torch.IntTensor(data), label\n","\n","#train, test dataset 선언\n","train_dataset = myDataset(train_df, tokenizer)\n","test_dataset = myDataset(test_df, tokenizer)\n","\n","#train, test dataloader 선언\n","batch_size = 100\n","train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size, shuffle=False)\n","\n","#잘 실행되는지 확인\n","for i in train_dataset:\n","  print(i[0].shape)\n","  print(i[1])\n","  break\n","\n","for i in train_dataloader:\n","  print(i[0].shape)\n","  print(i[1].shape)\n","  break"],"metadata":{"id":"8kWdTTr8XWal","colab":{"base_uri":"https://localhost:8080/","height":185,"referenced_widgets":["d2a9d2297aa84dd683f3f6bb0dbc230d","cb3090740af944b88c4f78bcc73c8dcb","b1dde845447c4720a68a65c92de3756b","434324aee8c64e69a2461aac2cb01615","f110a1a42d8143c9ad5ff492ec2d9503","ee1da2c558064178a410f87377e987a6","83d5c2ba42df4f8e90e6f0e54a7512f5","5e6245e939794bc582d1e81f2d88c140","b1ad802ff5df4a9e8b286fb6def4bb22","8350e6b79f96441b9aae5d8468036594","70eb0f05b6754a7ea674437f37571099","9c3e9a1d6e29430db997e745ba8ed908","21e6d4f38e86403180dbd41ab9256bd3","ff5fb30e50f6497bafb1e5103c60152b","58625762c81d4b269a24f1e7dc8f769e","d2a4f0e1c30748c4809468134ce52c63","b5193eb57c954812ad500df2ec6d344d","20b47cb8d136402385c120f01eaa13a4","c9461633fec44b108221f67ff27959b3","30edbe6000e44ed9a3c215e86a33694e","8fa83885400a4794883490a5c5ff9042","7f75b9d9b2b0414bbf8c0d2e77f75c1e","366cfb3e5aba4b498ea05c9bab08b712","b8b26ea308d141f5b4daa563804c9135","b3a04e4b8fad459099304f1c43ec3607","07bb5987f3c342ce993745d45b9ab861","7b8d5cbb61454d3599c2a7ed9a5c140f","c95d69c8cff54bd3a7cc4d20d797610c","dc478a75b972446a9397b23c88072dc3","da86cc95fa09436399590aca300b3348","69eb3f343a714aa5a7713a4df867de92","4a843d6721a143669b7a9a9c4c52e1e5","8be99872a8ad42ec992063e7bf60543c"]},"executionInfo":{"status":"ok","timestamp":1692721400777,"user_tz":-540,"elapsed":9729,"user":{"displayName":"Wooseok Kim (Wooseok)","userId":"10829587564796253131"}},"outputId":"44b596aa-8ab1-4696-9a19-ab7c0955bbd4"},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2a9d2297aa84dd683f3f6bb0dbc230d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c3e9a1d6e29430db997e745ba8ed908"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"366cfb3e5aba4b498ea05c9bab08b712"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["torch.Size([100])\n","0\n","torch.Size([100, 100])\n","torch.Size([100])\n"]}]},{"cell_type":"markdown","source":["#Model 구축\n","RNN/LSTM을 통해 text를 classification하는 model 선언\n","1. token의 index를 입력으로 받고 word embedding을 결과로 반환하는 nn.Embedding 사용 (128 차원의 embedding)\n","2. LSTM을 통해 모든 token을 입력 (128 차원의 hidden state)\n","3. many-to-one구조를 가지기 때문에 LSTM의 결과중 마지막 cell에 대한 결과만을 사용하여 nn.linear를통해 classification\n","\n","입력으로는 문장을 tokenziation과 indexing한게 입력으로 들어오기 때문에(batch, sequance length)형태의 입력  \n","이후 nn.Embedding을 거치면서 각 단어의 벡터가 생성되기 때문에(batch, sequance length, hidden size)의 형태로 nn.LSTM에 입력됨\n","\n","주요 obejct:  \n","**nn.Embedding:**https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html  \n","**nn.LSTM:**https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html  \n","**nn.RNN:**https://pytorch.org/docs/stable/generated/torch.nn.RNN.html"],"metadata":{"id":"xfKV9_575XYT"}},{"cell_type":"code","source":["from torch import nn\n","\n","class myModel(nn.Module):\n","    def __init__(self) -> None:\n","        super().__init__()\n","        self.embedding = nn.Embedding(50000, 128)\n","        self.lstm = nn.LSTM(128, 128)\n","        self.linear = nn.Linear(128, 2)\n","\n","    def forward(self, x):\n","        x = self.embedding(x)\n","        x, s = self.lstm(x)\n","        x = self.linear(x[:,-1,:])\n","        return x\n","\n","#Model 선언\n","model = myModel()\n","\n","#잘 실행되는지 확인\n","for i in train_dataloader:\n","  data = i[0]\n","  label = i[1]\n","  print(data.shape, label.shape)\n","  data = model(data)\n","  print(data.shape)\n","  break"],"metadata":{"id":"ss1jJefWEw6X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692719098879,"user_tz":-540,"elapsed":921,"user":{"displayName":"Wooseok Kim (Wooseok)","userId":"10829587564796253131"}},"outputId":"36ec4d00-7f85-48a3-a356-9b42d3f4ed88"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([100, 100]) torch.Size([100])\n","torch.Size([100, 2])\n"]}]},{"cell_type":"markdown","source":["#Main"],"metadata":{"id":"sg8IRfDM7Z_3"}},{"cell_type":"code","source":["from torch.optim import Adam\n","from torch.nn import CrossEntropyLoss\n","\n","#Model 선언\n","model = myModel().cuda()\n","\n","#학습을 위한 optimizer와 loss function 설정\n","optimizer = Adam(params=model.parameters(), lr=0.001)\n","lf = CrossEntropyLoss()\n","\n","#100번의 에폭을 실행\n","for e in range(100):\n","  print(\"\\nepoch \", e)\n","  epoch_loss = 0\n","  train_correct = 0\n","\n","  #선언한 모델 오브젝트를 학습가능한 상태로 변경\n","  model.train()\n","\n","  #모든 학습데이터에 대해서 학습\n","  for i in train_dataloader:\n","    #매 배치에 대한 gradient계산 이전에 optimizer에 저장된 이전 batch에 gradient를 삭제(초기화)\n","    optimizer.zero_grad()\n","\n","    data = i[0].cuda()\n","    target = i[1].cuda()\n","\n","    #결과 도출 및 정답수 연산\n","    output = model(data)\n","\n","    pred_label = torch.argmax(output, dim=-1)\n","    train_correct += sum(pred_label == target)\n","\n","    #loss연산\n","    loss = lf(output, target)\n","\n","    #loss backpropagation\n","    loss.backward()\n","\n","    #gradient update\n","    optimizer.step()\n","\n","    epoch_loss += loss.item()\n","\n","  print(train_correct)\n","  print(\"train loss\", epoch_loss/len(train_dataloader))\n","  print(\"train acc\", train_correct/len(train_dataset))\n","\n","  #model이 학습되지 않는 상태로 변경\n","  model.eval()\n","  test_loss = 0\n","  test_correct = 0\n","\n","  #gradient를 계산하지 않도록 하여 cost낭비 방지\n","  with torch.no_grad():\n","    #모든 test dataset에 대해서 결과연산\n","    for i in test_dataloader:\n","      data = i[0].cuda()\n","      target = i[1].cuda()\n","\n","      output = model(data)\n","\n","      loss = lf(output, target)\n","      pred_label = torch.argmax(output, dim=-1)\n","      test_correct += sum(pred_label==target)\n","      test_loss += loss.item()\n","\n","  print(\"test loss\", test_loss/len(test_dataloader))\n","  print(\"test acc\", test_correct/len(test_dataset))\n","\n"],"metadata":{"id":"zmVPBc1AN4j_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692719919937,"user_tz":-540,"elapsed":321247,"user":{"displayName":"Wooseok Kim (Wooseok)","userId":"10829587564796253131"}},"outputId":"a6f78585-27f7-41ee-cb56-efd5f1945edd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","epoch  0\n","tensor(3466, device='cuda:0')\n","train loss 0.4057011233597267\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.4014686793088913\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  1\n","tensor(3466, device='cuda:0')\n","train loss 0.39095816016197205\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.399105167016387\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  2\n","tensor(3466, device='cuda:0')\n","train loss 0.390461398334038\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39539206586778164\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  3\n","tensor(3466, device='cuda:0')\n","train loss 0.39041187159898805\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39580465108156204\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  4\n","tensor(3466, device='cuda:0')\n","train loss 0.43285836679179496\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39414174295961857\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  5\n","tensor(3466, device='cuda:0')\n","train loss 0.390869701780924\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3964254315942526\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  6\n","tensor(3466, device='cuda:0')\n","train loss 0.3897406807759913\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3948039673268795\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  7\n","tensor(3466, device='cuda:0')\n","train loss 0.3890899132664611\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3952280730009079\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  8\n","tensor(3466, device='cuda:0')\n","train loss 0.3886658472985756\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3940433971583843\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  9\n","tensor(3466, device='cuda:0')\n","train loss 0.38798154926881556\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3940373361110687\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  10\n","tensor(3466, device='cuda:0')\n","train loss 0.3883580271063781\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3940784242004156\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  11\n","tensor(3466, device='cuda:0')\n","train loss 0.38722088896646734\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39636140689253807\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  12\n","tensor(3466, device='cuda:0')\n","train loss 0.38756792937837\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3940951731055975\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  13\n","tensor(3466, device='cuda:0')\n","train loss 0.3881082320358695\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.394664965569973\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  14\n","tensor(3466, device='cuda:0')\n","train loss 0.38695989113028456\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39424682036042213\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  15\n","tensor(3466, device='cuda:0')\n","train loss 0.386713989624163\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39442106150090694\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  16\n","tensor(3466, device='cuda:0')\n","train loss 0.38693480048237777\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3947847820818424\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  17\n","tensor(3466, device='cuda:0')\n","train loss 0.3865313593570779\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3947604950517416\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  18\n","tensor(3466, device='cuda:0')\n","train loss 0.38673171928016153\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.395666915923357\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  19\n","tensor(3466, device='cuda:0')\n","train loss 0.3879916669755447\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39517177641391754\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  20\n","tensor(3466, device='cuda:0')\n","train loss 0.38588510090258066\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39458282105624676\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  21\n","tensor(3466, device='cuda:0')\n","train loss 0.3846557615097703\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3943837247788906\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  22\n","tensor(3466, device='cuda:0')\n","train loss 0.3858301241586848\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39620607532560825\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  23\n","tensor(3466, device='cuda:0')\n","train loss 0.38665307367720253\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3943668603897095\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  24\n","tensor(3466, device='cuda:0')\n","train loss 0.38575333702128106\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.394710049033165\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  25\n","tensor(3466, device='cuda:0')\n","train loss 0.38537141553512433\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3960723802447319\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  26\n","tensor(3466, device='cuda:0')\n","train loss 0.3876850045308834\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39651735685765743\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  27\n","tensor(3466, device='cuda:0')\n","train loss 0.3866234459891552\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.394818514585495\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  28\n","tensor(3466, device='cuda:0')\n","train loss 0.3871796578168869\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.394547738134861\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  29\n","tensor(3466, device='cuda:0')\n","train loss 0.3853291254944918\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3952895049005747\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  30\n","tensor(3466, device='cuda:0')\n","train loss 0.3863435994561126\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3952990099787712\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  31\n","tensor(3466, device='cuda:0')\n","train loss 0.3861398904061899\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3947639726102352\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  32\n","tensor(3466, device='cuda:0')\n","train loss 0.38579892639706775\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3947628401219845\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  33\n","tensor(3466, device='cuda:0')\n","train loss 0.3859658117701368\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39486394822597504\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  34\n","tensor(3466, device='cuda:0')\n","train loss 0.44838677891870826\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39755478128790855\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  35\n","tensor(3466, device='cuda:0')\n","train loss 0.39787643093888353\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39483097940683365\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  36\n","tensor(3466, device='cuda:0')\n","train loss 0.38787601597425414\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3941192179918289\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  37\n","tensor(3466, device='cuda:0')\n","train loss 0.38723474014096143\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39405826292932034\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  38\n","tensor(3466, device='cuda:0')\n","train loss 0.3877749650216684\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3942910712212324\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  39\n","tensor(3466, device='cuda:0')\n","train loss 0.4295807066487103\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39414517395198345\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  40\n","tensor(3466, device='cuda:0')\n","train loss 0.3898040870340859\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3941672332584858\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  41\n","tensor(3466, device='cuda:0')\n","train loss 0.3877384230131056\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39400689490139484\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  42\n","tensor(3466, device='cuda:0')\n","train loss 0.3874651502545287\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39403243735432625\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  43\n","tensor(3466, device='cuda:0')\n","train loss 0.4279824320862933\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3940267041325569\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  44\n","tensor(3466, device='cuda:0')\n","train loss 0.3886932134628296\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39402022399008274\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  45\n","tensor(3466, device='cuda:0')\n","train loss 0.38766525395032836\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3939975928515196\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  46\n","tensor(3466, device='cuda:0')\n","train loss 0.38780933509512644\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39402614533901215\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  47\n","tensor(3466, device='cuda:0')\n","train loss 0.3877145502625442\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39401907101273537\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  48\n","tensor(3466, device='cuda:0')\n","train loss 0.42686668692565544\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3940338473767042\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  49\n","tensor(3466, device='cuda:0')\n","train loss 0.39001827668852923\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3939950652420521\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  50\n","tensor(3466, device='cuda:0')\n","train loss 0.3877654151945579\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39401860162615776\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  51\n","tensor(3466, device='cuda:0')\n","train loss 0.38781278598599317\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39401004649698734\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  52\n","tensor(3466, device='cuda:0')\n","train loss 0.38800790469820906\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39400170370936394\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  53\n","tensor(3466, device='cuda:0')\n","train loss 0.387552963160887\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39403873682022095\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  54\n","tensor(3466, device='cuda:0')\n","train loss 0.4268945666348062\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39400634355843067\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  55\n","tensor(3466, device='cuda:0')\n","train loss 0.3890469237798598\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39399286545813084\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  56\n","tensor(3466, device='cuda:0')\n","train loss 0.3875596039905781\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3940664008259773\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  57\n","tensor(3466, device='cuda:0')\n","train loss 0.3880931680522314\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39399408362805843\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  58\n","tensor(3466, device='cuda:0')\n","train loss 0.3879419510684362\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39403925091028214\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  59\n","tensor(3466, device='cuda:0')\n","train loss 0.3876802943101743\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39406741224229336\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  60\n","tensor(3466, device='cuda:0')\n","train loss 0.38751865341895964\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3941026236861944\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  61\n","tensor(3466, device='cuda:0')\n","train loss 0.3873467750665618\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3940251711755991\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  62\n","tensor(3466, device='cuda:0')\n","train loss 0.387791971971349\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39401040598750114\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  63\n","tensor(3466, device='cuda:0')\n","train loss 0.38734297890488695\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39402653835713863\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  64\n","tensor(3466, device='cuda:0')\n","train loss 0.38746754061884997\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39404415525496006\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  65\n","tensor(3466, device='cuda:0')\n","train loss 0.38750808449780066\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3940099570900202\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  66\n","tensor(3466, device='cuda:0')\n","train loss 0.38737376688457115\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3940153308212757\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  67\n","tensor(3466, device='cuda:0')\n","train loss 0.3875723324897813\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39408668503165245\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  68\n","tensor(3466, device='cuda:0')\n","train loss 0.38684627522782583\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39409890584647655\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  69\n","tensor(3466, device='cuda:0')\n","train loss 0.3873206100812772\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39404289796948433\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  70\n","tensor(3466, device='cuda:0')\n","train loss 0.386656386823189\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3941991366446018\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  71\n","tensor(3466, device='cuda:0')\n","train loss 0.38731094213520606\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39409503526985645\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  72\n","tensor(3466, device='cuda:0')\n","train loss 0.38636116574450236\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39419946260750294\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  73\n","tensor(3466, device='cuda:0')\n","train loss 0.3863404255087783\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3942046146839857\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  74\n","tensor(3466, device='cuda:0')\n","train loss 0.3865964906971629\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3942728955298662\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  75\n","tensor(3466, device='cuda:0')\n","train loss 0.3859797296364133\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39442192763090134\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  76\n","tensor(3466, device='cuda:0')\n","train loss 0.3870452598827641\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39436129108071327\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  77\n","tensor(3466, device='cuda:0')\n","train loss 0.38527345548315745\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3950583189725876\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  78\n","tensor(3466, device='cuda:0')\n","train loss 0.3856610150598898\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3945254944264889\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  79\n","tensor(3466, device='cuda:0')\n","train loss 0.3859177482564275\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39456603676080704\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  80\n","tensor(3466, device='cuda:0')\n","train loss 0.3860261205856393\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3947460688650608\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  81\n","tensor(3466, device='cuda:0')\n","train loss 0.38610636279350374\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39499802328646183\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  82\n","tensor(3466, device='cuda:0')\n","train loss 0.3852598945178637\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39488746225833893\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  83\n","tensor(3466, device='cuda:0')\n","train loss 0.38589140954540996\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3954186271876097\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  84\n","tensor(3466, device='cuda:0')\n","train loss 0.386401866994253\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39488760754466057\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  85\n","tensor(3466, device='cuda:0')\n","train loss 0.38565155791073313\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3948463946580887\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  86\n","tensor(3466, device='cuda:0')\n","train loss 0.3847863250752775\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39493008702993393\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  87\n","tensor(3466, device='cuda:0')\n","train loss 0.38517691740175575\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3953867685049772\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  88\n","tensor(3466, device='cuda:0')\n","train loss 0.38430696362402383\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3951489981263876\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  89\n","tensor(3466, device='cuda:0')\n","train loss 0.3854771002036769\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3952549584209919\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  90\n","tensor(3466, device='cuda:0')\n","train loss 0.3863249666443685\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3954222649335861\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  91\n","tensor(3466, device='cuda:0')\n","train loss 0.38486517629608874\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3951255641877651\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  92\n","tensor(3466, device='cuda:0')\n","train loss 0.38587444139326493\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3950674273073673\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  93\n","tensor(3466, device='cuda:0')\n","train loss 0.45434943059595617\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39513298869132996\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  94\n","tensor(3466, device='cuda:0')\n","train loss 0.4313043094262844\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3940305020660162\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  95\n","tensor(3466, device='cuda:0')\n","train loss 0.3893152558948936\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3940039090812206\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  96\n","tensor(3466, device='cuda:0')\n","train loss 0.38787604614001947\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.3940046690404415\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  97\n","tensor(3466, device='cuda:0')\n","train loss 0.3877688424616325\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39399739168584347\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  98\n","tensor(3466, device='cuda:0')\n","train loss 0.38794791080602786\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39399054273962975\n","test acc tensor(0.8651, device='cuda:0')\n","\n","epoch  99\n","tensor(3466, device='cuda:0')\n","train loss 0.38744500352115163\n","train acc tensor(0.8663, device='cuda:0')\n","test loss 0.39399126172065735\n","test acc tensor(0.8651, device='cuda:0')\n"]}]}]}