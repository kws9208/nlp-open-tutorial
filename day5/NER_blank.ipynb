{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"iE84wKIhPFRh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693139538751,"user_tz":-540,"elapsed":22780,"user":{"displayName":"Wooseok Kim (Wooseok)","userId":"10829587564796253131"}},"outputId":"bb759b5b-466f-40d9-fa54-02fdebab20ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["#NER\n","각 단어가 어떠한 개체명(장소, 시간, 등)을 가르키는지를 확인하는 task  \n","dataset:https://www.kaggle.com/datasets/debasisdotcom/name-entity-recognition-ner-dataset\n","\n","##Data PreProcessing  \n","제공된 data는 이미 tokenization이 되어있는 형태로 제공된다.  \n","그렇기에 vocab dictionary를 직접 구성하고 각 tokenization된 token들을 indexing하여 숫자형태의 데이터로 변환환다.  \n","이때 class에 index를 부여해주는 scikit learn의 LabelEncoder를 사용해서 변환환다.  \n","또한 모든 token의 수를일정하게 맞춰주어야만 tensor 연산이 가능하기 때문에 <PAD>에 대한 indexing도 추가한다.\n"],"metadata":{"id":"-InH6nxeQFBx"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","from torch.utils.data import Dataset, DataLoader\n","import torch\n","\n","data_df = pd.read_csv(\"/content/drive/MyDrive/nlp-open-tutorial/5일차_배포/dataset/NER dataset.csv\", encoding=\"ISO-8859-1\").loc[:100000,:]\n","#print(data_df)\n","\n","#PAD를 추가하여 token에 index를 부여하기 위한 label encoder 학습\n","token_encoder = LabelEncoder()\n","token_encoder.fit([\"<PAD>\"]+list(map(lambda x: x.lower(),data_df.loc[:,\"Word\"])))\n","token_pad_index = token_encoder.transform([\"<PAD>\"])\n","#print(token_encoder.transform([\"<PAD>\"]))\n","\n","#PAD를 추가하여  label에 index를 부여하기 위한  label encoder 학습\n","label_encoder = LabelEncoder()\n","label_encoder.fit([\"<PAD>\"]+list(data_df.loc[:,\"Tag\"]))\n","label_pad_index = label_encoder.transform([\"<PAD>\"])\n","#print(label_encoder.transform([\"<PAD>\"]))\n","\n","data_list = []\n","label_list = []\n","for i in range(len(data_df)):\n","  if type(data_df.loc[i,\"Sentence #\"]) is str:\n","    data = []\n","    label = []\n","  data.append(data_df.loc[i,\"Word\"].lower())\n","  label.append(data_df.loc[i,\"Tag\"])\n","  if type(data_df.loc[i,\"Sentence #\"]) is str:\n","    data_list.append(data)\n","    label_list.append(label)\n","\n","data_list = list(map(token_encoder.transform, data_list))\n","label_list = list(map(label_encoder.transform, label_list))\n","\n","print(len(data_list))\n","print(len(label_list))"],"metadata":{"id":"GEETVzs0SNVX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693139594754,"user_tz":-540,"elapsed":56006,"user":{"displayName":"Wooseok Kim (Wooseok)","userId":"10829587564796253131"}},"outputId":"f9fd9815-145e-4877-9bae-d470647394bb"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["4544\n","4544\n"]}]},{"cell_type":"markdown","source":["##Dataset  \n","전체 데이터중 4000개의 data는 train 나머지는 test로 사용한다.  \n","사전에 tokenization과 indexing된 데이터의 크기를 맞추기위해 data에 padding을 추가한다.  \n","  padding의 value는 <PAD> token의 index를 사용한다."],"metadata":{"id":"9xuA7c2zaEir"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import DataLoader\n","import numpy as np\n","\n","#train_test_split\n","train_data_list = data_list[:4000]\n","test_data_list = data_list[4000:]\n","train_label_list = label_list[:4000]\n","test_label_list = label_list[4000:]\n","\n","class myDataset(Dataset):\n","  def __init__(self,data_list, label_list) -> None:\n","      super().__init__()\n","      self.data_list = data_list\n","      self.label_list = label_list\n","\n","  def __len__(self):\n","      return len(self.label_list)\n","\n","  def __getitem__(self, index):\n","\n","      data = torch.tensor(self.data_list[index])\n","      label = torch.tensor(self.label_list[index])\n","\n","      #make data with padding\n","      # data_pad = torch.tensor([token_pad_index] * (50 - len(data))).reshape(-1)\n","      # label_pad = torch.tensor([label_pad_index] * (50 - len(label))).reshape(-1)\n","      data_pad = torch.zeros(100,dtype=torch.int64) + token_pad_index\n","      label_pad = torch.zeros(100)+label_pad_index\n","\n","      # data = torch.LongTensor(np.concatenate([self.data_list[index], data_pad]))\n","      # label = torch.LongTensor(np.concatenate([self.label_list[index], label_pad]))\n","      data = torch.cat([torch.IntTensor(self.data_list[index]),data_pad])[:50]\n","      label = torch.cat([torch.IntTensor(self.label_list[index]),label_pad])[:50]\n","\n","      return data.flip(-1), label.flip(-1)\n","\n","train_dataset = myDataset(train_data_list, train_label_list)\n","test_dataset = myDataset(test_data_list, test_label_list)\n","\n","for i in train_dataset:\n","  print(i)\n","  print(i[0].shape, i[1].shape)\n","  break\n","\n","batch_size = 50\n","train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size, shuffle=False)\n","\n","for i in train_dataloader:\n","  print(i[0].shape)\n","  print(i[1].shape)\n","  break"],"metadata":{"id":"MWPogoV4hgTe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693139594754,"user_tz":-540,"elapsed":3,"user":{"displayName":"Wooseok Kim (Wooseok)","userId":"10829587564796253131"}},"outputId":"f4b17090-0b33-4574-c118-6d7e4ffd260f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["(tensor([ 487,  487,  487,  487,  487,  487,  487,  487,  487,  487,  487,  487,\n","         487,  487,  487,  487,  487,  487,  487,  487,  487,  487,  487,  487,\n","         487,  487,   15, 2530, 9163, 3983, 9403, 1687, 6432, 9973, 9165, 2803,\n","         933, 4970, 4744, 9813, 9165, 7228, 9254, 5570, 9217, 5741, 4409, 2824,\n","        6432, 9200]), tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n","         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 17., 17.,\n","        17., 17., 17.,  4., 17., 17., 17., 17., 17.,  3., 17., 17., 17., 17.,\n","        17.,  3., 17., 17., 17., 17., 17., 17.], dtype=torch.float64))\n","torch.Size([50]) torch.Size([50])\n","torch.Size([50, 50])\n","torch.Size([50, 50])\n"]}]},{"cell_type":"markdown","source":["##Model  \n","lstm을 위한 model과 seq2seq를 이용한 모델 두가지 구성  \n","seq2seq는 encoder model과 decoder model을 따로 구성하고 encoder model의 h,c를 decoder model의 입력으로 사용한다.  \n","이후 decoder model의 hidden state 들을 예측을 위해 사용한다."],"metadata":{"id":"IH33Yo4jqT19"}},{"cell_type":"markdown","source":["# LSTM 만들기"],"metadata":{"id":"f4Yz_iYwM2Jq"}},{"cell_type":"code","source":["from torch import nn\n","\n","class myModel(nn.Module):\n","  def __init__(self) -> None:\n","      super().__init__()\n","      self.emb = nn.Embedding(50000, 128)\n","      self.lstm = nn.LSTM(128, 128)\n","      self.ln1 = nn.Linear(128, 20)\n","\n","  def forward(self, x):\n","      x = self.emb(x)\n","      x, _ = self.lstm(x)\n","      x = self.ln1(x)\n","      return x\n","\n","model = myModel()\n","\n","for i in train_dataloader:\n","  print(i[0].shape)\n","  print(model(i[0]).shape)\n","  break"],"metadata":{"id":"TkwRy4S_mVw8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693139595246,"user_tz":-540,"elapsed":493,"user":{"displayName":"Wooseok Kim (Wooseok)","userId":"10829587564796253131"}},"outputId":"155cacb5-728a-4483-b190-91da01e41ac7"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([50, 50])\n","torch.Size([50, 50, 20])\n"]}]},{"cell_type":"markdown","source":["# LSTM을 bi-directional하게 만들기"],"metadata":{"id":"h-NkYKk-LrUe"}},{"cell_type":"code","source":["from torch import nn\n","\n","class myModel(nn.Module):\n","  def __init__(self) -> None:\n","      super().__init__()\n","      self.emb = nn.Embedding(50000, 128)\n","      self.lstm = nn.LSTM(128, 128, bidirectional=True)\n","      self.ln1 = nn.Linear(256, 20)\n","\n","  def forward(self, x):\n","      x = self.emb(x)\n","      x, _ = self.lstm(x)\n","      x = self.ln1(x)\n","      return x\n","\n","model = myModel()\n","\n","for i in train_dataloader:\n","  print(i[0].shape)\n","  print(model(i[0]).shape)\n","  break"],"metadata":{"id":"yqgzfvsAsTKv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693139595247,"user_tz":-540,"elapsed":8,"user":{"displayName":"Wooseok Kim (Wooseok)","userId":"10829587564796253131"}},"outputId":"88f54c57-eeb6-43d1-8c84-c4a48874c371"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([50, 50])\n","torch.Size([50, 50, 20])\n"]}]},{"cell_type":"markdown","source":["# Seq2seq는 encoder model과 decoder model로 구성"],"metadata":{"id":"btDRlwGdNXEr"}},{"cell_type":"code","source":["from torch import nn\n","\n","class myModel(nn.Module):\n","  def __init__(self) -> None:\n","      super().__init__()\n","      self.en_emb = nn.Embedding(50000, 128)\n","      self.en_lstm = nn.LSTM(128, 128, batch_first=True)\n","\n","      self.de_emb = nn.Embedding(50000, 128)\n","      self.de_lstm = nn.LSTM(128, 128, batch_first=True)\n","      self.de_ln1 = nn.Linear(128, 20)\n","\n","  def forward(self, x):\n","      x = self.en_emb(x)\n","      x, s = self.en_lstm(x)\n","      x, _ = self.de_lstm(x, s)\n","      x = self.de_ln1(x)\n","      return x\n","\n","model = myModel()\n","for i in train_dataloader:\n","  print(i[0].shape)\n","  print(model(i[0]).shape)\n","  break"],"metadata":{"id":"mkFLdrVVM79i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693139595247,"user_tz":-540,"elapsed":5,"user":{"displayName":"Wooseok Kim (Wooseok)","userId":"10829587564796253131"}},"outputId":"7c99ec01-8085-4eef-8452-3119654d2290"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([50, 50])\n","torch.Size([50, 50, 20])\n"]}]},{"cell_type":"markdown","source":["# Optimization"],"metadata":{"id":"xh6z1SkYqmJa"}},{"cell_type":"code","source":["from torch.optim import Adam\n","from torch.nn import CrossEntropyLoss\n","\n","model = myModel()\n","model.cuda()\n","\n","#학습을 위한 optimizer와 loss function 설정 (learning rate 0.0001)\n","optimizer = Adam(params=model.parameters(), lr=0.001)\n","lf = CrossEntropyLoss()\n","\n","\n","#100번의 에폭을 실행\n","for e in range(100):\n","  print(\"\\nepoch \", e)\n","  epoch_loss = 0\n","  train_correct = 0\n","\n","  #선언한 모델 오브젝트를 학습가능한 상태로 변경\n","  model.train()\n","\n","  #모든 학습데이터에 대해서 학습\n","  for i in train_dataloader:\n","    #매 배치에 대한 gradient계산 이전에 optimizer에 저장된 이전 batch에 gradient를 삭제(초기화)\n","    optimizer.zero_grad()\n","\n","    data = i[0].cuda()\n","    target = i[1].reshape(-1).cuda()\n","    #print(target.shape)\n","\n","    #결과 도출 및 정답수 연산\n","    output = model(data).reshape(-1,20)\n","    pred_label = torch.argmax(output, dim=-1)\n","    train_correct += sum(pred_label == target)\n","\n","    #loss연산\n","    loss = lf(output, target.long())\n","\n","    #loss backpropagation\n","    loss.backward()\n","\n","    #gradient update\n","    optimizer.step()\n","    epoch_loss += loss.item()\n","\n","  print(\"train loss\", epoch_loss/len(train_dataloader))\n","  print(\"train acc\", train_correct/len(train_dataset))\n","\n","  #model이 학습되지 않는 상태로 변경\n","  model.eval()\n","  test_loss = 0\n","  test_correct = 0\n","\n","  #gradient를 계산하지 않도록 하여 cost낭비 방지\n","  with torch.no_grad():\n","    #모든 test dataset에 대해서 결과연산\n","    for i in test_dataloader:\n","      test_data = i[0].cuda()\n","      test_target = i[1].reshape(-1).cuda()\n","      #print(test_target.shape)\n","\n","      # model에 입력하기\n","      output = model(test_data).reshape(-1,20)\n","      pred_label = torch.argmax(output, dim=-1)\n","      test_correct += sum(pred_label == test_target)\n","\n","      # loss 계산\n","      loss = lf(output, test_target.long())\n","      test_loss += loss.item()\n","\n","\n","  print(\"test loss\", test_loss/len(test_dataloader))\n","  print(\"test acc\", test_correct/len(test_dataset))\n","\n"],"metadata":{"id":"9p02322wqs1k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693140403719,"user_tz":-540,"elapsed":353120,"user":{"displayName":"Wooseok Kim (Wooseok)","userId":"10829587564796253131"}},"outputId":"3e17f9f3-4513-45be-d28a-a431baa826ed"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","epoch  0\n","train loss 0.7071731425821781\n","train acc tensor(42.6100, device='cuda:0')\n","test loss 0.3403932343829762\n","test acc tensor(46.5938, device='cuda:0')\n","\n","epoch  1\n","train loss 0.31540982276201246\n","train acc tensor(46.6425, device='cuda:0')\n","test loss 0.29928819699720904\n","test acc tensor(46.5938, device='cuda:0')\n","\n","epoch  2\n","train loss 0.26506723258644344\n","train acc tensor(46.6555, device='cuda:0')\n","test loss 0.25639824298295105\n","test acc tensor(46.6599, device='cuda:0')\n","\n","epoch  3\n","train loss 0.2262372164055705\n","train acc tensor(46.9350, device='cuda:0')\n","test loss 0.23207912661812521\n","test acc tensor(47.0037, device='cuda:0')\n","\n","epoch  4\n","train loss 0.19969641733914614\n","train acc tensor(47.2103, device='cuda:0')\n","test loss 0.21429807354103436\n","test acc tensor(47.1783, device='cuda:0')\n","\n","epoch  5\n","train loss 0.17775826025754213\n","train acc tensor(47.4913, device='cuda:0')\n","test loss 0.20211015099828894\n","test acc tensor(47.4540, device='cuda:0')\n","\n","epoch  6\n","train loss 0.1565058244392276\n","train acc tensor(47.8550, device='cuda:0')\n","test loss 0.18833140216090463\n","test acc tensor(47.6140, device='cuda:0')\n","\n","epoch  7\n","train loss 0.13627526443451643\n","train acc tensor(48.1368, device='cuda:0')\n","test loss 0.1767460365187038\n","test acc tensor(47.7371, device='cuda:0')\n","\n","epoch  8\n","train loss 0.1187177112326026\n","train acc tensor(48.3873, device='cuda:0')\n","test loss 0.1707438975572586\n","test acc tensor(47.8971, device='cuda:0')\n","\n","epoch  9\n","train loss 0.104567816760391\n","train acc tensor(48.5928, device='cuda:0')\n","test loss 0.16977444020184604\n","test acc tensor(47.9320, device='cuda:0')\n","\n","epoch  10\n","train loss 0.09193337559700013\n","train acc tensor(48.7510, device='cuda:0')\n","test loss 0.16857083141803741\n","test acc tensor(47.9412, device='cuda:0')\n","\n","epoch  11\n","train loss 0.08120894553139806\n","train acc tensor(48.8815, device='cuda:0')\n","test loss 0.17046442221511493\n","test acc tensor(47.9688, device='cuda:0')\n","\n","epoch  12\n","train loss 0.07181100235320628\n","train acc tensor(49.0040, device='cuda:0')\n","test loss 0.17478437992659482\n","test acc tensor(47.9577, device='cuda:0')\n","\n","epoch  13\n","train loss 0.06301335138268768\n","train acc tensor(49.1343, device='cuda:0')\n","test loss 0.18241466310891238\n","test acc tensor(47.8732, device='cuda:0')\n","\n","epoch  14\n","train loss 0.055288767674937844\n","train acc tensor(49.2408, device='cuda:0')\n","test loss 0.18515099720521408\n","test acc tensor(47.8621, device='cuda:0')\n","\n","epoch  15\n","train loss 0.049456932302564385\n","train acc tensor(49.3190, device='cuda:0')\n","test loss 0.18978129462762314\n","test acc tensor(47.9669, device='cuda:0')\n","\n","epoch  16\n","train loss 0.04251147140748799\n","train acc tensor(49.4238, device='cuda:0')\n","test loss 0.1983270211653276\n","test acc tensor(47.9173, device='cuda:0')\n","\n","epoch  17\n","train loss 0.03691457773093134\n","train acc tensor(49.5100, device='cuda:0')\n","test loss 0.20208317312327298\n","test acc tensor(47.9945, device='cuda:0')\n","\n","epoch  18\n","train loss 0.03225999604910612\n","train acc tensor(49.5780, device='cuda:0')\n","test loss 0.20972385867075485\n","test acc tensor(47.9430, device='cuda:0')\n","\n","epoch  19\n","train loss 0.027539983089081944\n","train acc tensor(49.6535, device='cuda:0')\n","test loss 0.21339788762005893\n","test acc tensor(47.9320, device='cuda:0')\n","\n","epoch  20\n","train loss 0.023655660357326268\n","train acc tensor(49.7005, device='cuda:0')\n","test loss 0.2268624170259996\n","test acc tensor(47.9375, device='cuda:0')\n","\n","epoch  21\n","train loss 0.020017232780810447\n","train acc tensor(49.7530, device='cuda:0')\n","test loss 0.22951560670679266\n","test acc tensor(47.9393, device='cuda:0')\n","\n","epoch  22\n","train loss 0.017385457857744768\n","train acc tensor(49.7893, device='cuda:0')\n","test loss 0.23304263705557043\n","test acc tensor(47.8603, device='cuda:0')\n","\n","epoch  23\n","train loss 0.015314138156827539\n","train acc tensor(49.8090, device='cuda:0')\n","test loss 0.23753427917307074\n","test acc tensor(47.8989, device='cuda:0')\n","\n","epoch  24\n","train loss 0.013298761297482998\n","train acc tensor(49.8385, device='cuda:0')\n","test loss 0.24494278160008517\n","test acc tensor(47.9412, device='cuda:0')\n","\n","epoch  25\n","train loss 0.01196174586075358\n","train acc tensor(49.8545, device='cuda:0')\n","test loss 0.24947597763755106\n","test acc tensor(47.9228, device='cuda:0')\n","\n","epoch  26\n","train loss 0.010617600279510952\n","train acc tensor(49.8715, device='cuda:0')\n","test loss 0.2494034401395104\n","test acc tensor(47.8438, device='cuda:0')\n","\n","epoch  27\n","train loss 0.009541050950065254\n","train acc tensor(49.8863, device='cuda:0')\n","test loss 0.25633991441943427\n","test acc tensor(47.9210, device='cuda:0')\n","\n","epoch  28\n","train loss 0.00820025081629865\n","train acc tensor(49.9020, device='cuda:0')\n","test loss 0.26003087108785455\n","test acc tensor(47.9320, device='cuda:0')\n","\n","epoch  29\n","train loss 0.00728185151820071\n","train acc tensor(49.9148, device='cuda:0')\n","test loss 0.26532460478219116\n","test acc tensor(47.8842, device='cuda:0')\n","\n","epoch  30\n","train loss 0.006457388872513547\n","train acc tensor(49.9255, device='cuda:0')\n","test loss 0.26817216791889886\n","test acc tensor(47.9228, device='cuda:0')\n","\n","epoch  31\n","train loss 0.005838002631207928\n","train acc tensor(49.9320, device='cuda:0')\n","test loss 0.2683114450086247\n","test acc tensor(47.8640, device='cuda:0')\n","\n","epoch  32\n","train loss 0.005257849585905206\n","train acc tensor(49.9390, device='cuda:0')\n","test loss 0.27671460671858356\n","test acc tensor(47.8658, device='cuda:0')\n","\n","epoch  33\n","train loss 0.004877257606131025\n","train acc tensor(49.9460, device='cuda:0')\n","test loss 0.27903359044681897\n","test acc tensor(47.9173, device='cuda:0')\n","\n","epoch  34\n","train loss 0.004652286453347187\n","train acc tensor(49.9460, device='cuda:0')\n","test loss 0.2780951965938915\n","test acc tensor(47.9026, device='cuda:0')\n","\n","epoch  35\n","train loss 0.0041783474429394115\n","train acc tensor(49.9503, device='cuda:0')\n","test loss 0.28457335179502313\n","test acc tensor(47.8603, device='cuda:0')\n","\n","epoch  36\n","train loss 0.0038363561645383014\n","train acc tensor(49.9540, device='cuda:0')\n","test loss 0.29089511118151923\n","test acc tensor(47.8915, device='cuda:0')\n","\n","epoch  37\n","train loss 0.0034866983725805765\n","train acc tensor(49.9598, device='cuda:0')\n","test loss 0.2871615250002254\n","test acc tensor(47.8732, device='cuda:0')\n","\n","epoch  38\n","train loss 0.0032570017647230998\n","train acc tensor(49.9603, device='cuda:0')\n","test loss 0.29398122294382617\n","test acc tensor(47.8015, device='cuda:0')\n","\n","epoch  39\n","train loss 0.003081072628265247\n","train acc tensor(49.9653, device='cuda:0')\n","test loss 0.29623396830125287\n","test acc tensor(47.9136, device='cuda:0')\n","\n","epoch  40\n","train loss 0.0030254084631451406\n","train acc tensor(49.9660, device='cuda:0')\n","test loss 0.2979321154681119\n","test acc tensor(47.9062, device='cuda:0')\n","\n","epoch  41\n","train loss 0.003301126114092767\n","train acc tensor(49.9623, device='cuda:0')\n","test loss 0.2966061451218345\n","test acc tensor(47.8364, device='cuda:0')\n","\n","epoch  42\n","train loss 0.003398433147231117\n","train acc tensor(49.9608, device='cuda:0')\n","test loss 0.30516283214092255\n","test acc tensor(47.9228, device='cuda:0')\n","\n","epoch  43\n","train loss 0.0030576718163501937\n","train acc tensor(49.9630, device='cuda:0')\n","test loss 0.3060094971548427\n","test acc tensor(47.8438, device='cuda:0')\n","\n","epoch  44\n","train loss 0.0029557752393884586\n","train acc tensor(49.9650, device='cuda:0')\n","test loss 0.31235806237567554\n","test acc tensor(47.6562, device='cuda:0')\n","\n","epoch  45\n","train loss 0.002917562474613078\n","train acc tensor(49.9655, device='cuda:0')\n","test loss 0.3075383779677478\n","test acc tensor(47.8290, device='cuda:0')\n","\n","epoch  46\n","train loss 0.0021059692902781536\n","train acc tensor(49.9760, device='cuda:0')\n","test loss 0.3092430369420485\n","test acc tensor(47.8603, device='cuda:0')\n","\n","epoch  47\n","train loss 0.0016282842123473528\n","train acc tensor(49.9825, device='cuda:0')\n","test loss 0.3133524426005103\n","test acc tensor(47.9412, device='cuda:0')\n","\n","epoch  48\n","train loss 0.0016307009984302568\n","train acc tensor(49.9835, device='cuda:0')\n","test loss 0.3143685487183658\n","test acc tensor(47.9228, device='cuda:0')\n","\n","epoch  49\n","train loss 0.0013157760564354247\n","train acc tensor(49.9835, device='cuda:0')\n","test loss 0.31707982177084143\n","test acc tensor(47.8511, device='cuda:0')\n","\n","epoch  50\n","train loss 0.0011605657666223124\n","train acc tensor(49.9865, device='cuda:0')\n","test loss 0.32016952064904297\n","test acc tensor(47.9210, device='cuda:0')\n","\n","epoch  51\n","train loss 0.0011175653442478505\n","train acc tensor(49.9875, device='cuda:0')\n","test loss 0.3255111967975443\n","test acc tensor(47.9485, device='cuda:0')\n","\n","epoch  52\n","train loss 0.001049224856978981\n","train acc tensor(49.9885, device='cuda:0')\n","test loss 0.32894632626663556\n","test acc tensor(47.9577, device='cuda:0')\n","\n","epoch  53\n","train loss 0.0009493197536357912\n","train acc tensor(49.9888, device='cuda:0')\n","test loss 0.32666924731297925\n","test acc tensor(47.9118, device='cuda:0')\n","\n","epoch  54\n","train loss 0.0008683598527568393\n","train acc tensor(49.9883, device='cuda:0')\n","test loss 0.3261338025331497\n","test acc tensor(47.9026, device='cuda:0')\n","\n","epoch  55\n","train loss 0.0008125336667944794\n","train acc tensor(49.9908, device='cuda:0')\n","test loss 0.3398910869251598\n","test acc tensor(47.9320, device='cuda:0')\n","\n","epoch  56\n","train loss 0.0010056470597191946\n","train acc tensor(49.9883, device='cuda:0')\n","test loss 0.3285989327864213\n","test acc tensor(47.8989, device='cuda:0')\n","\n","epoch  57\n","train loss 0.0007765161859424552\n","train acc tensor(49.9905, device='cuda:0')\n","test loss 0.33148003301837226\n","test acc tensor(47.9283, device='cuda:0')\n","\n","epoch  58\n","train loss 0.0006763771962141618\n","train acc tensor(49.9935, device='cuda:0')\n","test loss 0.3348738361488689\n","test acc tensor(47.9246, device='cuda:0')\n","\n","epoch  59\n","train loss 0.0006442440948376315\n","train acc tensor(49.9925, device='cuda:0')\n","test loss 0.3367757119915702\n","test acc tensor(47.8952, device='cuda:0')\n","\n","epoch  60\n","train loss 0.0006179194228025153\n","train acc tensor(49.9950, device='cuda:0')\n","test loss 0.34215048497373407\n","test acc tensor(47.9320, device='cuda:0')\n","\n","epoch  61\n","train loss 0.0005903376042624587\n","train acc tensor(49.9933, device='cuda:0')\n","test loss 0.3413477675481276\n","test acc tensor(47.8750, device='cuda:0')\n","\n","epoch  62\n","train loss 0.002008195019516279\n","train acc tensor(49.9725, device='cuda:0')\n","test loss 0.3457646803422408\n","test acc tensor(47.8290, device='cuda:0')\n","\n","epoch  63\n","train loss 0.010236682454706169\n","train acc tensor(49.8343, device='cuda:0')\n","test loss 0.33429069410670886\n","test acc tensor(47.7353, device='cuda:0')\n","\n","epoch  64\n","train loss 0.006265172502025962\n","train acc tensor(49.8988, device='cuda:0')\n","test loss 0.3305191167376258\n","test acc tensor(47.8107, device='cuda:0')\n","\n","epoch  65\n","train loss 0.0026041426201118155\n","train acc tensor(49.9643, device='cuda:0')\n","test loss 0.3299140605059537\n","test acc tensor(47.9044, device='cuda:0')\n","\n","epoch  66\n","train loss 0.0010977809550240635\n","train acc tensor(49.9873, device='cuda:0')\n","test loss 0.33618970892646094\n","test acc tensor(47.8768, device='cuda:0')\n","\n","epoch  67\n","train loss 0.0005777250411483692\n","train acc tensor(49.9943, device='cuda:0')\n","test loss 0.3400769585912878\n","test acc tensor(47.8603, device='cuda:0')\n","\n","epoch  68\n","train loss 0.0005153094145498472\n","train acc tensor(49.9948, device='cuda:0')\n","test loss 0.34213083711537445\n","test acc tensor(47.8879, device='cuda:0')\n","\n","epoch  69\n","train loss 0.0004188534148852341\n","train acc tensor(49.9968, device='cuda:0')\n","test loss 0.34176727587526495\n","test acc tensor(47.8952, device='cuda:0')\n","\n","epoch  70\n","train loss 0.0004192266575046233\n","train acc tensor(49.9953, device='cuda:0')\n","test loss 0.35147853872992774\n","test acc tensor(47.9191, device='cuda:0')\n","\n","epoch  71\n","train loss 0.00039170156005639\n","train acc tensor(49.9955, device='cuda:0')\n","test loss 0.34694155237891455\n","test acc tensor(47.8879, device='cuda:0')\n","\n","epoch  72\n","train loss 0.00034825861648641877\n","train acc tensor(49.9968, device='cuda:0')\n","test loss 0.35047104412859137\n","test acc tensor(47.8842, device='cuda:0')\n","\n","epoch  73\n","train loss 0.0003114500364063133\n","train acc tensor(49.9970, device='cuda:0')\n","test loss 0.35302009094845166\n","test acc tensor(47.9099, device='cuda:0')\n","\n","epoch  74\n","train loss 0.0002748998749666498\n","train acc tensor(49.9975, device='cuda:0')\n","test loss 0.35365009849721735\n","test acc tensor(47.9173, device='cuda:0')\n","\n","epoch  75\n","train loss 0.00025874048187688457\n","train acc tensor(49.9980, device='cuda:0')\n","test loss 0.3542930483818054\n","test acc tensor(47.9062, device='cuda:0')\n","\n","epoch  76\n","train loss 0.0002597093473013956\n","train acc tensor(49.9978, device='cuda:0')\n","test loss 0.35833186182108795\n","test acc tensor(47.9062, device='cuda:0')\n","\n","epoch  77\n","train loss 0.00024142904621839988\n","train acc tensor(49.9978, device='cuda:0')\n","test loss 0.36028583483262494\n","test acc tensor(47.9210, device='cuda:0')\n","\n","epoch  78\n","train loss 0.00023775424829182158\n","train acc tensor(49.9983, device='cuda:0')\n","test loss 0.36166052655740216\n","test acc tensor(47.9191, device='cuda:0')\n","\n","epoch  79\n","train loss 0.0002109184745222592\n","train acc tensor(49.9978, device='cuda:0')\n","test loss 0.3653450228951194\n","test acc tensor(47.9007, device='cuda:0')\n","\n","epoch  80\n","train loss 0.00022208049995242618\n","train acc tensor(49.9983, device='cuda:0')\n","test loss 0.36651543053713714\n","test acc tensor(47.8713, device='cuda:0')\n","\n","epoch  81\n","train loss 0.00021718088846682803\n","train acc tensor(49.9980, device='cuda:0')\n","test loss 0.36797574162483215\n","test acc tensor(47.9044, device='cuda:0')\n","\n","epoch  82\n","train loss 0.00019855138134516892\n","train acc tensor(49.9990, device='cuda:0')\n","test loss 0.36926835775375366\n","test acc tensor(47.9081, device='cuda:0')\n","\n","epoch  83\n","train loss 0.00018592727383293095\n","train acc tensor(49.9983, device='cuda:0')\n","test loss 0.3741825141689994\n","test acc tensor(47.8952, device='cuda:0')\n","\n","epoch  84\n","train loss 0.00017782591517061518\n","train acc tensor(49.9980, device='cuda:0')\n","test loss 0.3687028641050512\n","test acc tensor(47.8934, device='cuda:0')\n","\n","epoch  85\n","train loss 0.00017565315047249897\n","train acc tensor(49.9985, device='cuda:0')\n","test loss 0.3686681714924899\n","test acc tensor(47.8971, device='cuda:0')\n","\n","epoch  86\n","train loss 0.00017470853804297805\n","train acc tensor(49.9980, device='cuda:0')\n","test loss 0.3724076504057104\n","test acc tensor(47.9154, device='cuda:0')\n","\n","epoch  87\n","train loss 0.0002497800414403173\n","train acc tensor(49.9978, device='cuda:0')\n","test loss 0.3741233132102273\n","test acc tensor(47.8732, device='cuda:0')\n","\n","epoch  88\n","train loss 0.000183463052303523\n","train acc tensor(49.9980, device='cuda:0')\n","test loss 0.3772543153979562\n","test acc tensor(47.9320, device='cuda:0')\n","\n","epoch  89\n","train loss 0.00032251139391519245\n","train acc tensor(49.9965, device='cuda:0')\n","test loss 0.37709216367114673\n","test acc tensor(47.8732, device='cuda:0')\n","\n","epoch  90\n","train loss 0.0014452481707849074\n","train acc tensor(49.9780, device='cuda:0')\n","test loss 0.38246531919999555\n","test acc tensor(47.8971, device='cuda:0')\n","\n","epoch  91\n","train loss 0.006733954555238597\n","train acc tensor(49.8943, device='cuda:0')\n","test loss 0.365351140499115\n","test acc tensor(47.9099, device='cuda:0')\n","\n","epoch  92\n","train loss 0.004536045809800271\n","train acc tensor(49.9270, device='cuda:0')\n","test loss 0.36076775193214417\n","test acc tensor(47.9375, device='cuda:0')\n","\n","epoch  93\n","train loss 0.0021118341475812484\n","train acc tensor(49.9695, device='cuda:0')\n","test loss 0.3661322160200639\n","test acc tensor(47.9596, device='cuda:0')\n","\n","epoch  94\n","train loss 0.0008472832330880919\n","train acc tensor(49.9913, device='cuda:0')\n","test loss 0.3719528750939803\n","test acc tensor(47.9154, device='cuda:0')\n","\n","epoch  95\n","train loss 0.0004182699028206116\n","train acc tensor(49.9965, device='cuda:0')\n","test loss 0.367948827418414\n","test acc tensor(47.9320, device='cuda:0')\n","\n","epoch  96\n","train loss 0.00020429086544027086\n","train acc tensor(49.9980, device='cuda:0')\n","test loss 0.37246123498136346\n","test acc tensor(47.9540, device='cuda:0')\n","\n","epoch  97\n","train loss 0.00017771063576219604\n","train acc tensor(49.9978, device='cuda:0')\n","test loss 0.374247206882997\n","test acc tensor(47.9338, device='cuda:0')\n","\n","epoch  98\n","train loss 0.00015943176485961886\n","train acc tensor(49.9985, device='cuda:0')\n","test loss 0.3781511458483609\n","test acc tensor(47.9357, device='cuda:0')\n","\n","epoch  99\n","train loss 0.00013865792461729143\n","train acc tensor(49.9985, device='cuda:0')\n","test loss 0.37971414761109784\n","test acc tensor(47.9301, device='cuda:0')\n"]}]}]}